{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d70d0d-c70c-4bab-97d4-9c2810457493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "/environment/miniconda3/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "/environment/miniconda3/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating nms_1d_cpu.egg-info\n",
      "writing nms_1d_cpu.egg-info/PKG-INFO\n",
      "writing dependency_links to nms_1d_cpu.egg-info/dependency_links.txt\n",
      "writing top-level names to nms_1d_cpu.egg-info/top_level.txt\n",
      "writing manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
      "/environment/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "reading manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
      "writing manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_ext\n",
      "building 'nms_1d_cpu' extension\n",
      "creating build\n",
      "creating build/temp.linux-x86_64-cpython-310\n",
      "creating build/temp.linux-x86_64-cpython-310/home\n",
      "creating build/temp.linux-x86_64-cpython-310/home/featurize\n",
      "creating build/temp.linux-x86_64-cpython-310/home/featurize/TriDet\n",
      "creating build/temp.linux-x86_64-cpython-310/home/featurize/TriDet/libs\n",
      "creating build/temp.linux-x86_64-cpython-310/home/featurize/TriDet/libs/utils\n",
      "creating build/temp.linux-x86_64-cpython-310/home/featurize/TriDet/libs/utils/csrc\n",
      "gcc -pthread -B /environment/miniconda3/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /environment/miniconda3/include -fPIC -O2 -isystem /environment/miniconda3/include -fPIC -I/environment/miniconda3/lib/python3.10/site-packages/torch/include -I/environment/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/environment/miniconda3/lib/python3.10/site-packages/torch/include/TH -I/environment/miniconda3/lib/python3.10/site-packages/torch/include/THC -I/environment/miniconda3/include/python3.10 -c /home/featurize/TriDet/libs/utils/csrc/nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/home/featurize/TriDet/libs/utils/csrc/nms_cpu.o -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_1d_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "creating build/lib.linux-x86_64-cpython-310\n",
      "g++ -pthread -B /environment/miniconda3/compiler_compat -shared -Wl,-rpath,/environment/miniconda3/lib -Wl,-rpath-link,/environment/miniconda3/lib -L/environment/miniconda3/lib -Wl,-rpath,/environment/miniconda3/lib -Wl,-rpath-link,/environment/miniconda3/lib -L/environment/miniconda3/lib build/temp.linux-x86_64-cpython-310/home/featurize/TriDet/libs/utils/csrc/nms_cpu.o -L/environment/miniconda3/lib/python3.10/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/nms_1d_cpu.cpython-310-x86_64-linux-gnu.so\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-cpython-310/nms_1d_cpu.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating stub loader for nms_1d_cpu.cpython-310-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/nms_1d_cpu.py to nms_1d_cpu.cpython-310.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying nms_1d_cpu.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying nms_1d_cpu.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying nms_1d_cpu.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying nms_1d_cpu.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.nms_1d_cpu.cpython-310: module references __file__\n",
      "creating dist\n",
      "creating 'dist/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
      "removing '/home/featurize/work/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg' (and everything under it)\n",
      "creating /home/featurize/work/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
      "Extracting nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg to /home/featurize/work/.local/lib/python3.10/site-packages\n",
      "Adding nms-1d-cpu 0.0.0 to easy-install.pth file\n",
      "\n",
      "Installed /home/featurize/work/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
      "Processing dependencies for nms-1d-cpu==0.0.0\n",
      "Finished processing dependencies for nms-1d-cpu==0.0.0\n"
     ]
    }
   ],
   "source": [
    "!python /home/featurize/TriDet/libs/utils/setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c11a65c-f295-4a9a-ab69-a74d16c9cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "{'dataset': {'crop_ratio': [0.9, 1.0],\n",
      "             'default_fps': 30,\n",
      "             'downsample_rate': 1,\n",
      "             'feat_folder': './data/epic_kitchens/features',\n",
      "             'feat_stride': 16,\n",
      "             'file_ext': '.npz',\n",
      "             'file_prefix': None,\n",
      "             'force_upsampling': False,\n",
      "             'input_dim': 2304,\n",
      "             'json_file': './data/epic_kitchens/annotations/epic_kitchens_100_noun.json',\n",
      "             'max_seq_len': 2304,\n",
      "             'num_classes': 300,\n",
      "             'num_frames': 32,\n",
      "             'trunc_thresh': 0.3},\n",
      " 'dataset_name': 'epic',\n",
      " 'devices': ['cuda:0'],\n",
      " 'init_rand_seed': 1234567891,\n",
      " 'loader': {'batch_size': 2, 'num_workers': 4},\n",
      " 'model': {'backbone_arch': (2, 2, 5),\n",
      "           'backbone_type': 'SGP',\n",
      "           'boudary_kernel_size': 3,\n",
      "           'downsample_type': 'max',\n",
      "           'embd_dim': 512,\n",
      "           'embd_kernel_size': 3,\n",
      "           'embd_with_ln': True,\n",
      "           'fpn_dim': 512,\n",
      "           'fpn_type': 'identity',\n",
      "           'fpn_with_ln': True,\n",
      "           'head_dim': 512,\n",
      "           'head_kernel_size': 3,\n",
      "           'head_num_layers': 3,\n",
      "           'head_with_ln': True,\n",
      "           'init_conv_vars': 0,\n",
      "           'input_dim': 2304,\n",
      "           'input_noise': 0,\n",
      "           'iou_weight_power': 0.25,\n",
      "           'k': 4,\n",
      "           'max_buffer_len_factor': 4.0,\n",
      "           'max_seq_len': 2304,\n",
      "           'n_sgp_win_size': 1,\n",
      "           'num_bins': 16,\n",
      "           'num_classes': 300,\n",
      "           'regression_range': [[0, 4],\n",
      "                                [2, 8],\n",
      "                                [4, 16],\n",
      "                                [8, 32],\n",
      "                                [16, 64],\n",
      "                                [32, 10000]],\n",
      "           'scale_factor': 2,\n",
      "           'sgp_mlp_dim': 1024,\n",
      "           'test_cfg': {'duration_thresh': 0.05,\n",
      "                        'ext_score_file': None,\n",
      "                        'iou_threshold': 0.1,\n",
      "                        'max_seg_num': 2000,\n",
      "                        'min_score': 0.001,\n",
      "                        'multiclass_nms': True,\n",
      "                        'nms_method': 'soft',\n",
      "                        'nms_sigma': 0.4,\n",
      "                        'pre_nms_thresh': 0.001,\n",
      "                        'pre_nms_topk': 5000,\n",
      "                        'voting_thresh': 0.75},\n",
      "           'train_cfg': {'center_sample': 'radius',\n",
      "                         'center_sample_radius': 1.5,\n",
      "                         'clip_grad_l2norm': 1.0,\n",
      "                         'cls_prior_prob': 0.01,\n",
      "                         'dropout': 0.0,\n",
      "                         'droppath': 0.1,\n",
      "                         'head_empty_cls': [],\n",
      "                         'init_loss_norm': 250,\n",
      "                         'label_smoothing': 0.1,\n",
      "                         'loss_weight': 1.0},\n",
      "           'use_abs_pe': False,\n",
      "           'use_trident_head': True},\n",
      " 'model_name': 'TriDet',\n",
      " 'opt': {'epochs': 14,\n",
      "         'eta_min': 1e-08,\n",
      "         'learning_rate': 0.0001,\n",
      "         'momentum': 0.9,\n",
      "         'schedule_gamma': 0.1,\n",
      "         'schedule_steps': [],\n",
      "         'schedule_type': 'cosine',\n",
      "         'type': 'AdamW',\n",
      "         'warmup': True,\n",
      "         'warmup_epochs': 5,\n",
      "         'weight_decay': 0.05},\n",
      " 'output_folder': './ckpt/',\n",
      " 'test_cfg': {'duration_thresh': 0.05,\n",
      "              'ext_score_file': None,\n",
      "              'iou_threshold': 0.1,\n",
      "              'max_seg_num': 2000,\n",
      "              'min_score': 0.001,\n",
      "              'multiclass_nms': True,\n",
      "              'nms_method': 'soft',\n",
      "              'nms_sigma': 0.4,\n",
      "              'pre_nms_thresh': 0.001,\n",
      "              'pre_nms_topk': 5000,\n",
      "              'voting_thresh': 0.75},\n",
      " 'train_cfg': {'center_sample': 'radius',\n",
      "               'center_sample_radius': 1.5,\n",
      "               'clip_grad_l2norm': 1.0,\n",
      "               'cls_prior_prob': 0.01,\n",
      "               'dropout': 0.0,\n",
      "               'droppath': 0.1,\n",
      "               'head_empty_cls': [],\n",
      "               'init_loss_norm': 250,\n",
      "               'label_smoothing': 0.1,\n",
      "               'loss_weight': 1.0},\n",
      " 'train_split': ['training'],\n",
      " 'val_split': ['validation']}\n",
      "Using model EMA ...\n",
      "\n",
      "Start training model TriDet ...\n",
      "\n",
      "[Train]: Epoch 0 started\n",
      "Epoch: [000][00010/00247]\tTime 0.90 (0.90)\tLoss 0.79 (0.79)\n",
      "\t\tcls_loss 0.35 (0.35)\treg_loss 0.44 (0.44)\n",
      "Epoch: [000][00020/00247]\tTime 0.32 (0.61)\tLoss 0.57 (0.68)\n",
      "\t\tcls_loss 0.24 (0.30)\treg_loss 0.32 (0.38)\n",
      "Epoch: [000][00030/00247]\tTime 0.32 (0.51)\tLoss 3.03 (1.46)\n",
      "\t\tcls_loss 1.31 (0.64)\treg_loss 1.72 (0.83)\n",
      "Epoch: [000][00040/00247]\tTime 0.31 (0.46)\tLoss 1.67 (1.51)\n",
      "\t\tcls_loss 0.72 (0.66)\treg_loss 0.94 (0.86)\n",
      "Epoch: [000][00050/00247]\tTime 0.32 (0.43)\tLoss 1.77 (1.57)\n",
      "\t\tcls_loss 0.80 (0.69)\treg_loss 0.98 (0.88)\n",
      "Epoch: [000][00060/00247]\tTime 0.32 (0.41)\tLoss 0.47 (1.38)\n",
      "\t\tcls_loss 0.20 (0.61)\treg_loss 0.26 (0.78)\n",
      "Epoch: [000][00070/00247]\tTime 0.31 (0.40)\tLoss 1.94 (1.46)\n",
      "\t\tcls_loss 0.87 (0.64)\treg_loss 1.08 (0.82)\n",
      "Epoch: [000][00080/00247]\tTime 0.31 (0.39)\tLoss 1.20 (1.43)\n",
      "\t\tcls_loss 0.57 (0.63)\treg_loss 0.63 (0.80)\n",
      "Epoch: [000][00090/00247]\tTime 0.33 (0.38)\tLoss 1.30 (1.41)\n",
      "\t\tcls_loss 0.67 (0.64)\treg_loss 0.64 (0.78)\n",
      "Epoch: [000][00100/00247]\tTime 0.31 (0.37)\tLoss 2.45 (1.52)\n",
      "\t\tcls_loss 1.39 (0.71)\treg_loss 1.06 (0.81)\n",
      "Epoch: [000][00110/00247]\tTime 0.32 (0.37)\tLoss 1.07 (1.48)\n",
      "\t\tcls_loss 0.60 (0.70)\treg_loss 0.46 (0.78)\n",
      "Epoch: [000][00120/00247]\tTime 0.32 (0.36)\tLoss 0.97 (1.43)\n",
      "\t\tcls_loss 0.56 (0.69)\treg_loss 0.41 (0.74)\n",
      "Epoch: [000][00130/00247]\tTime 0.33 (0.36)\tLoss 1.13 (1.41)\n",
      "\t\tcls_loss 0.64 (0.69)\treg_loss 0.48 (0.72)\n",
      "Epoch: [000][00140/00247]\tTime 0.31 (0.36)\tLoss 1.20 (1.40)\n",
      "\t\tcls_loss 0.69 (0.69)\treg_loss 0.50 (0.71)\n",
      "Epoch: [000][00150/00247]\tTime 0.30 (0.35)\tLoss 2.18 (1.45)\n",
      "\t\tcls_loss 1.24 (0.72)\treg_loss 0.94 (0.72)\n",
      "Epoch: [000][00160/00247]\tTime 0.30 (0.35)\tLoss 1.37 (1.44)\n",
      "\t\tcls_loss 0.75 (0.73)\treg_loss 0.62 (0.72)\n",
      "Epoch: [000][00170/00247]\tTime 0.31 (0.35)\tLoss 1.32 (1.44)\n",
      "\t\tcls_loss 0.75 (0.73)\treg_loss 0.58 (0.71)\n",
      "Epoch: [000][00180/00247]\tTime 0.32 (0.35)\tLoss 0.59 (1.39)\n",
      "\t\tcls_loss 0.30 (0.70)\treg_loss 0.29 (0.69)\n",
      "Epoch: [000][00190/00247]\tTime 0.31 (0.34)\tLoss 1.26 (1.38)\n",
      "\t\tcls_loss 0.70 (0.70)\treg_loss 0.56 (0.68)\n",
      "Epoch: [000][00200/00247]\tTime 0.31 (0.34)\tLoss 2.01 (1.41)\n",
      "\t\tcls_loss 1.06 (0.72)\treg_loss 0.95 (0.69)\n",
      "Epoch: [000][00210/00247]\tTime 0.31 (0.34)\tLoss 1.73 (1.43)\n",
      "\t\tcls_loss 0.97 (0.73)\treg_loss 0.75 (0.70)\n",
      "Epoch: [000][00220/00247]\tTime 0.32 (0.34)\tLoss 0.33 (1.38)\n",
      "\t\tcls_loss 0.15 (0.71)\treg_loss 0.19 (0.67)\n",
      "Epoch: [000][00230/00247]\tTime 0.33 (0.34)\tLoss 0.56 (1.34)\n",
      "\t\tcls_loss 0.28 (0.69)\treg_loss 0.28 (0.66)\n",
      "Epoch: [000][00240/00247]\tTime 0.31 (0.34)\tLoss 0.95 (1.33)\n",
      "\t\tcls_loss 0.52 (0.68)\treg_loss 0.42 (0.65)\n",
      "[Train]: Epoch 0 finished with lr=0.00002002\n",
      "\n",
      "\n",
      "[Train]: Epoch 1 started\n",
      "Epoch: [001][00010/00247]\tTime 0.35 (0.35)\tLoss 1.27 (1.27)\n",
      "\t\tcls_loss 0.64 (0.64)\treg_loss 0.63 (0.63)\n",
      "Epoch: [001][00020/00247]\tTime 0.33 (0.34)\tLoss 0.93 (1.10)\n",
      "\t\tcls_loss 0.42 (0.53)\treg_loss 0.51 (0.57)\n",
      "Epoch: [001][00030/00247]\tTime 0.32 (0.33)\tLoss 0.12 (0.77)\n",
      "\t\tcls_loss 0.04 (0.37)\treg_loss 0.08 (0.41)\n",
      "Epoch: [001][00040/00247]\tTime 0.31 (0.33)\tLoss 2.20 (1.13)\n",
      "\t\tcls_loss 1.15 (0.56)\treg_loss 1.04 (0.56)\n",
      "Epoch: [001][00050/00247]\tTime 0.31 (0.32)\tLoss 1.26 (1.15)\n",
      "\t\tcls_loss 0.56 (0.56)\treg_loss 0.70 (0.59)\n",
      "Epoch: [001][00060/00247]\tTime 0.31 (0.32)\tLoss 0.80 (1.09)\n",
      "\t\tcls_loss 0.37 (0.53)\treg_loss 0.43 (0.56)\n",
      "Epoch: [001][00070/00247]\tTime 0.32 (0.32)\tLoss 0.16 (0.96)\n",
      "\t\tcls_loss 0.07 (0.46)\treg_loss 0.09 (0.50)\n",
      "Epoch: [001][00080/00247]\tTime 0.31 (0.32)\tLoss 0.68 (0.93)\n",
      "\t\tcls_loss 0.35 (0.45)\treg_loss 0.34 (0.48)\n",
      "Epoch: [001][00090/00247]\tTime 0.32 (0.32)\tLoss 0.94 (0.93)\n",
      "\t\tcls_loss 0.43 (0.45)\treg_loss 0.52 (0.48)\n",
      "Epoch: [001][00100/00247]\tTime 0.32 (0.32)\tLoss 0.14 (0.85)\n",
      "\t\tcls_loss 0.07 (0.41)\treg_loss 0.07 (0.44)\n",
      "Epoch: [001][00110/00247]\tTime 0.31 (0.32)\tLoss 0.42 (0.81)\n",
      "\t\tcls_loss 0.22 (0.39)\treg_loss 0.20 (0.42)\n",
      "Epoch: [001][00120/00247]\tTime 0.30 (0.32)\tLoss 0.17 (0.76)\n",
      "\t\tcls_loss 0.07 (0.37)\treg_loss 0.10 (0.39)\n",
      "Epoch: [001][00130/00247]\tTime 0.30 (0.32)\tLoss 1.54 (0.82)\n",
      "\t\tcls_loss 0.76 (0.40)\treg_loss 0.78 (0.42)\n",
      "Epoch: [001][00140/00247]\tTime 0.30 (0.32)\tLoss 0.47 (0.79)\n",
      "\t\tcls_loss 0.20 (0.38)\treg_loss 0.27 (0.41)\n",
      "Epoch: [001][00150/00247]\tTime 0.32 (0.32)\tLoss 1.19 (0.82)\n",
      "\t\tcls_loss 0.63 (0.40)\treg_loss 0.56 (0.42)\n",
      "Epoch: [001][00160/00247]\tTime 0.31 (0.32)\tLoss 0.10 (0.77)\n",
      "\t\tcls_loss 0.04 (0.38)\treg_loss 0.06 (0.40)\n",
      "Epoch: [001][00170/00247]\tTime 0.33 (0.32)\tLoss 0.24 (0.74)\n",
      "\t\tcls_loss 0.12 (0.36)\treg_loss 0.12 (0.38)\n",
      "Epoch: [001][00180/00247]\tTime 0.34 (0.32)\tLoss 0.26 (0.72)\n",
      "\t\tcls_loss 0.14 (0.35)\treg_loss 0.12 (0.37)\n",
      "Epoch: [001][00190/00247]\tTime 0.33 (0.32)\tLoss 0.73 (0.72)\n",
      "\t\tcls_loss 0.34 (0.35)\treg_loss 0.39 (0.37)\n",
      "Epoch: [001][00200/00247]\tTime 0.32 (0.32)\tLoss 0.74 (0.72)\n",
      "\t\tcls_loss 0.35 (0.35)\treg_loss 0.39 (0.37)\n",
      "Epoch: [001][00210/00247]\tTime 0.32 (0.32)\tLoss 1.12 (0.74)\n",
      "\t\tcls_loss 0.56 (0.36)\treg_loss 0.56 (0.38)\n",
      "Epoch: [001][00220/00247]\tTime 0.33 (0.32)\tLoss 1.12 (0.75)\n",
      "\t\tcls_loss 0.52 (0.37)\treg_loss 0.60 (0.39)\n",
      "Epoch: [001][00230/00247]\tTime 0.32 (0.32)\tLoss 1.95 (0.81)\n",
      "\t\tcls_loss 0.99 (0.39)\treg_loss 0.96 (0.41)\n",
      "Epoch: [001][00240/00247]\tTime 0.33 (0.32)\tLoss 0.51 (0.79)\n",
      "\t\tcls_loss 0.28 (0.39)\treg_loss 0.24 (0.41)\n",
      "[Train]: Epoch 1 finished with lr=0.00004003\n",
      "\n",
      "\n",
      "[Train]: Epoch 2 started\n",
      "Epoch: [002][00010/00247]\tTime 0.37 (0.37)\tLoss 0.71 (0.71)\n",
      "\t\tcls_loss 0.34 (0.34)\treg_loss 0.37 (0.37)\n",
      "Epoch: [002][00020/00247]\tTime 0.33 (0.35)\tLoss 0.95 (0.83)\n",
      "\t\tcls_loss 0.45 (0.40)\treg_loss 0.50 (0.44)\n",
      "Epoch: [002][00030/00247]\tTime 0.33 (0.34)\tLoss 0.20 (0.62)\n",
      "\t\tcls_loss 0.09 (0.30)\treg_loss 0.11 (0.33)\n",
      "Epoch: [002][00040/00247]\tTime 0.32 (0.34)\tLoss 0.81 (0.67)\n",
      "\t\tcls_loss 0.35 (0.31)\treg_loss 0.46 (0.36)\n",
      "Epoch: [002][00050/00247]\tTime 0.32 (0.33)\tLoss 0.16 (0.57)\n",
      "\t\tcls_loss 0.07 (0.26)\treg_loss 0.09 (0.31)\n",
      "Epoch: [002][00060/00247]\tTime 0.31 (0.33)\tLoss 0.60 (0.57)\n",
      "\t\tcls_loss 0.28 (0.26)\treg_loss 0.33 (0.31)\n",
      "Epoch: [002][00070/00247]\tTime 0.30 (0.33)\tLoss 0.83 (0.61)\n",
      "\t\tcls_loss 0.43 (0.29)\treg_loss 0.40 (0.32)\n",
      "Epoch: [002][00080/00247]\tTime 0.31 (0.32)\tLoss 0.70 (0.62)\n",
      "\t\tcls_loss 0.33 (0.29)\treg_loss 0.37 (0.33)\n",
      "Epoch: [002][00090/00247]\tTime 0.32 (0.32)\tLoss 0.28 (0.58)\n",
      "\t\tcls_loss 0.15 (0.28)\treg_loss 0.12 (0.31)\n",
      "Epoch: [002][00100/00247]\tTime 0.32 (0.32)\tLoss 1.23 (0.65)\n",
      "\t\tcls_loss 0.62 (0.31)\treg_loss 0.61 (0.34)\n",
      "Epoch: [002][00110/00247]\tTime 0.31 (0.32)\tLoss 0.61 (0.65)\n",
      "\t\tcls_loss 0.28 (0.31)\treg_loss 0.34 (0.34)\n",
      "Epoch: [002][00120/00247]\tTime 0.31 (0.32)\tLoss 0.93 (0.67)\n",
      "\t\tcls_loss 0.46 (0.32)\treg_loss 0.47 (0.35)\n",
      "Epoch: [002][00130/00247]\tTime 0.30 (0.32)\tLoss 0.34 (0.64)\n",
      "\t\tcls_loss 0.16 (0.31)\treg_loss 0.18 (0.34)\n",
      "Epoch: [002][00140/00247]\tTime 0.31 (0.32)\tLoss 0.60 (0.64)\n",
      "\t\tcls_loss 0.32 (0.31)\treg_loss 0.28 (0.33)\n",
      "Epoch: [002][00150/00247]\tTime 0.32 (0.32)\tLoss 1.53 (0.70)\n",
      "\t\tcls_loss 0.76 (0.34)\treg_loss 0.77 (0.36)\n",
      "Epoch: [002][00160/00247]\tTime 0.32 (0.32)\tLoss 0.46 (0.69)\n",
      "\t\tcls_loss 0.21 (0.33)\treg_loss 0.25 (0.35)\n",
      "Epoch: [002][00170/00247]\tTime 0.32 (0.32)\tLoss 0.64 (0.68)\n",
      "\t\tcls_loss 0.33 (0.33)\treg_loss 0.31 (0.35)\n",
      "Epoch: [002][00180/00247]\tTime 0.33 (0.32)\tLoss 0.74 (0.69)\n",
      "\t\tcls_loss 0.43 (0.34)\treg_loss 0.31 (0.35)\n",
      "Epoch: [002][00190/00247]\tTime 0.32 (0.32)\tLoss 0.30 (0.67)\n",
      "\t\tcls_loss 0.11 (0.32)\treg_loss 0.19 (0.34)\n",
      "Epoch: [002][00200/00247]\tTime 0.31 (0.32)\tLoss 0.19 (0.64)\n",
      "\t\tcls_loss 0.09 (0.31)\treg_loss 0.09 (0.33)\n",
      "Epoch: [002][00210/00247]\tTime 0.31 (0.32)\tLoss 0.90 (0.65)\n",
      "\t\tcls_loss 0.45 (0.32)\treg_loss 0.44 (0.33)\n",
      "Epoch: [002][00220/00247]\tTime 0.31 (0.32)\tLoss 0.20 (0.63)\n",
      "\t\tcls_loss 0.10 (0.31)\treg_loss 0.10 (0.32)\n",
      "Epoch: [002][00230/00247]\tTime 0.31 (0.32)\tLoss 1.68 (0.68)\n",
      "\t\tcls_loss 0.78 (0.33)\treg_loss 0.90 (0.35)\n",
      "Epoch: [002][00240/00247]\tTime 0.31 (0.32)\tLoss 0.13 (0.66)\n",
      "\t\tcls_loss 0.07 (0.32)\treg_loss 0.06 (0.34)\n",
      "[Train]: Epoch 2 finished with lr=0.00006005\n",
      "\n",
      "\n",
      "[Train]: Epoch 3 started\n",
      "Epoch: [003][00010/00247]\tTime 0.34 (0.34)\tLoss 0.24 (0.24)\n",
      "\t\tcls_loss 0.13 (0.13)\treg_loss 0.11 (0.11)\n",
      "Epoch: [003][00020/00247]\tTime 0.31 (0.32)\tLoss 1.41 (0.82)\n",
      "\t\tcls_loss 0.68 (0.40)\treg_loss 0.73 (0.42)\n",
      "Epoch: [003][00030/00247]\tTime 0.32 (0.32)\tLoss 0.29 (0.65)\n",
      "\t\tcls_loss 0.16 (0.32)\treg_loss 0.13 (0.32)\n",
      "Epoch: [003][00040/00247]\tTime 0.32 (0.32)\tLoss 0.53 (0.62)\n",
      "\t\tcls_loss 0.24 (0.30)\treg_loss 0.29 (0.32)\n",
      "Epoch: [003][00050/00247]\tTime 0.32 (0.32)\tLoss 1.18 (0.73)\n",
      "\t\tcls_loss 0.57 (0.36)\treg_loss 0.61 (0.37)\n",
      "Epoch: [003][00060/00247]\tTime 0.30 (0.32)\tLoss 0.39 (0.67)\n",
      "\t\tcls_loss 0.18 (0.33)\treg_loss 0.21 (0.35)\n",
      "Epoch: [003][00070/00247]\tTime 0.31 (0.32)\tLoss 0.94 (0.71)\n",
      "\t\tcls_loss 0.42 (0.34)\treg_loss 0.52 (0.37)\n",
      "Epoch: [003][00080/00247]\tTime 0.31 (0.32)\tLoss 0.76 (0.72)\n",
      "\t\tcls_loss 0.38 (0.34)\treg_loss 0.38 (0.37)\n",
      "Epoch: [003][00090/00247]\tTime 0.31 (0.32)\tLoss 0.76 (0.72)\n",
      "\t\tcls_loss 0.38 (0.35)\treg_loss 0.39 (0.37)\n",
      "Epoch: [003][00100/00247]\tTime 0.31 (0.32)\tLoss 1.11 (0.76)\n",
      "\t\tcls_loss 0.54 (0.37)\treg_loss 0.56 (0.39)\n",
      "Epoch: [003][00110/00247]\tTime 0.31 (0.32)\tLoss 1.03 (0.78)\n",
      "\t\tcls_loss 0.48 (0.38)\treg_loss 0.55 (0.41)\n",
      "Epoch: [003][00120/00247]\tTime 0.31 (0.31)\tLoss 1.38 (0.83)\n",
      "\t\tcls_loss 0.64 (0.40)\treg_loss 0.74 (0.44)\n",
      "Epoch: [003][00130/00247]\tTime 0.31 (0.31)\tLoss 0.44 (0.80)\n",
      "\t\tcls_loss 0.22 (0.39)\treg_loss 0.22 (0.42)\n",
      "Epoch: [003][00140/00247]\tTime 0.32 (0.32)\tLoss 0.26 (0.77)\n",
      "\t\tcls_loss 0.14 (0.37)\treg_loss 0.13 (0.40)\n",
      "Epoch: [003][00150/00247]\tTime 0.33 (0.32)\tLoss 1.04 (0.78)\n",
      "\t\tcls_loss 0.45 (0.37)\treg_loss 0.60 (0.41)\n",
      "Epoch: [003][00160/00247]\tTime 0.31 (0.32)\tLoss 1.03 (0.80)\n",
      "\t\tcls_loss 0.53 (0.38)\treg_loss 0.50 (0.42)\n",
      "Epoch: [003][00170/00247]\tTime 0.32 (0.32)\tLoss 0.56 (0.79)\n",
      "\t\tcls_loss 0.23 (0.37)\treg_loss 0.33 (0.41)\n",
      "Epoch: [003][00180/00247]\tTime 0.32 (0.32)\tLoss 0.23 (0.75)\n",
      "\t\tcls_loss 0.12 (0.36)\treg_loss 0.11 (0.39)\n",
      "Epoch: [003][00190/00247]\tTime 0.33 (0.32)\tLoss 0.87 (0.76)\n",
      "\t\tcls_loss 0.43 (0.36)\treg_loss 0.44 (0.40)\n",
      "Epoch: [003][00200/00247]\tTime 0.32 (0.32)\tLoss 0.27 (0.74)\n",
      "\t\tcls_loss 0.14 (0.35)\treg_loss 0.14 (0.38)\n",
      "Epoch: [003][00210/00247]\tTime 0.33 (0.32)\tLoss 0.91 (0.74)\n",
      "\t\tcls_loss 0.45 (0.36)\treg_loss 0.46 (0.39)\n",
      "Epoch: [003][00220/00247]\tTime 0.32 (0.32)\tLoss 0.68 (0.74)\n",
      "\t\tcls_loss 0.27 (0.35)\treg_loss 0.41 (0.39)\n",
      "Epoch: [003][00230/00247]\tTime 0.33 (0.32)\tLoss 0.96 (0.75)\n",
      "\t\tcls_loss 0.51 (0.36)\treg_loss 0.45 (0.39)\n",
      "Epoch: [003][00240/00247]\tTime 0.31 (0.32)\tLoss 0.53 (0.74)\n",
      "\t\tcls_loss 0.26 (0.36)\treg_loss 0.27 (0.39)\n",
      "[Train]: Epoch 3 finished with lr=0.00008006\n",
      "\n",
      "\n",
      "[Train]: Epoch 4 started\n",
      "Epoch: [004][00010/00247]\tTime 0.36 (0.36)\tLoss 0.70 (0.70)\n",
      "\t\tcls_loss 0.37 (0.37)\treg_loss 0.33 (0.33)\n",
      "Epoch: [004][00020/00247]\tTime 0.31 (0.34)\tLoss 0.61 (0.66)\n",
      "\t\tcls_loss 0.32 (0.35)\treg_loss 0.29 (0.31)\n",
      "Epoch: [004][00030/00247]\tTime 0.32 (0.33)\tLoss 0.97 (0.76)\n",
      "\t\tcls_loss 0.48 (0.39)\treg_loss 0.49 (0.37)\n",
      "Epoch: [004][00040/00247]\tTime 0.32 (0.33)\tLoss 0.08 (0.59)\n",
      "\t\tcls_loss 0.04 (0.30)\treg_loss 0.04 (0.29)\n",
      "Epoch: [004][00050/00247]\tTime 0.32 (0.33)\tLoss 0.29 (0.53)\n",
      "\t\tcls_loss 0.14 (0.27)\treg_loss 0.16 (0.26)\n",
      "Epoch: [004][00060/00247]\tTime 0.31 (0.33)\tLoss 0.62 (0.55)\n",
      "\t\tcls_loss 0.29 (0.27)\treg_loss 0.34 (0.27)\n",
      "Epoch: [004][00070/00247]\tTime 0.32 (0.32)\tLoss 0.44 (0.53)\n",
      "\t\tcls_loss 0.20 (0.26)\treg_loss 0.24 (0.27)\n",
      "Epoch: [004][00080/00247]\tTime 0.32 (0.32)\tLoss 1.02 (0.59)\n",
      "\t\tcls_loss 0.50 (0.29)\treg_loss 0.52 (0.30)\n",
      "Epoch: [004][00090/00247]\tTime 0.31 (0.32)\tLoss 1.17 (0.66)\n",
      "\t\tcls_loss 0.48 (0.31)\treg_loss 0.69 (0.34)\n",
      "Epoch: [004][00100/00247]\tTime 0.32 (0.32)\tLoss 0.73 (0.66)\n",
      "\t\tcls_loss 0.38 (0.32)\treg_loss 0.35 (0.34)\n",
      "Epoch: [004][00110/00247]\tTime 0.32 (0.32)\tLoss 0.20 (0.62)\n",
      "\t\tcls_loss 0.10 (0.30)\treg_loss 0.10 (0.32)\n",
      "Epoch: [004][00120/00247]\tTime 0.31 (0.32)\tLoss 0.69 (0.63)\n",
      "\t\tcls_loss 0.32 (0.30)\treg_loss 0.37 (0.33)\n",
      "Epoch: [004][00130/00247]\tTime 0.31 (0.32)\tLoss 1.12 (0.67)\n",
      "\t\tcls_loss 0.58 (0.32)\treg_loss 0.54 (0.34)\n",
      "Epoch: [004][00140/00247]\tTime 0.31 (0.32)\tLoss 0.73 (0.67)\n",
      "\t\tcls_loss 0.37 (0.33)\treg_loss 0.36 (0.34)\n",
      "Epoch: [004][00150/00247]\tTime 0.31 (0.32)\tLoss 1.01 (0.69)\n",
      "\t\tcls_loss 0.46 (0.34)\treg_loss 0.55 (0.36)\n",
      "Epoch: [004][00160/00247]\tTime 0.32 (0.32)\tLoss 0.33 (0.67)\n",
      "\t\tcls_loss 0.15 (0.32)\treg_loss 0.18 (0.35)\n",
      "Epoch: [004][00170/00247]\tTime 0.32 (0.32)\tLoss 0.78 (0.68)\n",
      "\t\tcls_loss 0.37 (0.33)\treg_loss 0.41 (0.35)\n",
      "Epoch: [004][00180/00247]\tTime 0.32 (0.32)\tLoss 0.53 (0.67)\n",
      "\t\tcls_loss 0.26 (0.32)\treg_loss 0.26 (0.35)\n",
      "Epoch: [004][00190/00247]\tTime 0.33 (0.32)\tLoss 0.57 (0.66)\n",
      "\t\tcls_loss 0.29 (0.32)\treg_loss 0.29 (0.34)\n",
      "Epoch: [004][00200/00247]\tTime 0.33 (0.32)\tLoss 0.28 (0.64)\n",
      "\t\tcls_loss 0.15 (0.31)\treg_loss 0.13 (0.33)\n",
      "Epoch: [004][00210/00247]\tTime 0.33 (0.32)\tLoss 0.93 (0.66)\n",
      "\t\tcls_loss 0.55 (0.32)\treg_loss 0.38 (0.33)\n",
      "Epoch: [004][00220/00247]\tTime 0.32 (0.32)\tLoss 0.75 (0.66)\n",
      "\t\tcls_loss 0.31 (0.32)\treg_loss 0.44 (0.34)\n",
      "Epoch: [004][00230/00247]\tTime 0.31 (0.32)\tLoss 1.93 (0.72)\n",
      "\t\tcls_loss 0.87 (0.35)\treg_loss 1.06 (0.37)\n",
      "Epoch: [004][00240/00247]\tTime 0.32 (0.32)\tLoss 0.48 (0.71)\n",
      "\t\tcls_loss 0.26 (0.34)\treg_loss 0.23 (0.36)\n",
      "[Train]: Epoch 4 finished with lr=0.00010000\n",
      "\n",
      "\n",
      "[Train]: Epoch 5 started\n",
      "Epoch: [005][00010/00247]\tTime 0.36 (0.36)\tLoss 0.57 (0.57)\n",
      "\t\tcls_loss 0.30 (0.30)\treg_loss 0.27 (0.27)\n",
      "Epoch: [005][00020/00247]\tTime 0.33 (0.34)\tLoss 1.03 (0.80)\n",
      "\t\tcls_loss 0.47 (0.39)\treg_loss 0.57 (0.42)\n",
      "Epoch: [005][00030/00247]\tTime 0.32 (0.34)\tLoss 0.44 (0.68)\n",
      "\t\tcls_loss 0.20 (0.32)\treg_loss 0.24 (0.36)\n",
      "Epoch: [005][00040/00247]\tTime 0.32 (0.33)\tLoss 0.98 (0.76)\n",
      "\t\tcls_loss 0.51 (0.37)\treg_loss 0.47 (0.39)\n",
      "Epoch: [005][00050/00247]\tTime 0.33 (0.33)\tLoss 0.83 (0.77)\n",
      "\t\tcls_loss 0.42 (0.38)\treg_loss 0.41 (0.39)\n",
      "Epoch: [005][00060/00247]\tTime 0.33 (0.33)\tLoss 0.63 (0.75)\n",
      "\t\tcls_loss 0.34 (0.37)\treg_loss 0.30 (0.37)\n",
      "Epoch: [005][00070/00247]\tTime 0.33 (0.33)\tLoss 0.92 (0.77)\n",
      "\t\tcls_loss 0.40 (0.38)\treg_loss 0.52 (0.40)\n",
      "Epoch: [005][00080/00247]\tTime 0.33 (0.33)\tLoss 0.62 (0.75)\n",
      "\t\tcls_loss 0.30 (0.37)\treg_loss 0.31 (0.39)\n",
      "Epoch: [005][00090/00247]\tTime 0.33 (0.33)\tLoss 0.42 (0.72)\n",
      "\t\tcls_loss 0.22 (0.35)\treg_loss 0.20 (0.36)\n",
      "Epoch: [005][00100/00247]\tTime 0.33 (0.33)\tLoss 0.21 (0.67)\n",
      "\t\tcls_loss 0.12 (0.33)\treg_loss 0.09 (0.34)\n",
      "Epoch: [005][00110/00247]\tTime 0.33 (0.33)\tLoss 0.73 (0.67)\n",
      "\t\tcls_loss 0.31 (0.33)\treg_loss 0.41 (0.34)\n",
      "Epoch: [005][00120/00247]\tTime 0.32 (0.33)\tLoss 0.45 (0.65)\n",
      "\t\tcls_loss 0.23 (0.32)\treg_loss 0.23 (0.33)\n",
      "Epoch: [005][00130/00247]\tTime 0.31 (0.33)\tLoss 0.13 (0.61)\n",
      "\t\tcls_loss 0.06 (0.30)\treg_loss 0.07 (0.31)\n",
      "Epoch: [005][00140/00247]\tTime 0.31 (0.33)\tLoss 0.28 (0.59)\n",
      "\t\tcls_loss 0.16 (0.29)\treg_loss 0.12 (0.30)\n",
      "Epoch: [005][00150/00247]\tTime 0.31 (0.32)\tLoss 0.22 (0.56)\n",
      "\t\tcls_loss 0.12 (0.28)\treg_loss 0.10 (0.29)\n",
      "Epoch: [005][00160/00247]\tTime 0.31 (0.32)\tLoss 0.87 (0.58)\n",
      "\t\tcls_loss 0.41 (0.28)\treg_loss 0.47 (0.30)\n",
      "Epoch: [005][00170/00247]\tTime 0.31 (0.32)\tLoss 0.11 (0.55)\n",
      "\t\tcls_loss 0.05 (0.27)\treg_loss 0.06 (0.28)\n",
      "Epoch: [005][00180/00247]\tTime 0.31 (0.32)\tLoss 0.78 (0.57)\n",
      "\t\tcls_loss 0.39 (0.28)\treg_loss 0.39 (0.29)\n",
      "Epoch: [005][00190/00247]\tTime 0.31 (0.32)\tLoss 0.22 (0.55)\n",
      "\t\tcls_loss 0.11 (0.27)\treg_loss 0.11 (0.28)\n",
      "Epoch: [005][00200/00247]\tTime 0.31 (0.32)\tLoss 0.26 (0.53)\n",
      "\t\tcls_loss 0.15 (0.26)\treg_loss 0.11 (0.27)\n",
      "Epoch: [005][00210/00247]\tTime 0.31 (0.32)\tLoss 0.27 (0.52)\n",
      "\t\tcls_loss 0.14 (0.26)\treg_loss 0.13 (0.26)\n",
      "Epoch: [005][00220/00247]\tTime 0.31 (0.32)\tLoss 0.13 (0.50)\n",
      "\t\tcls_loss 0.06 (0.25)\treg_loss 0.07 (0.26)\n",
      "Epoch: [005][00230/00247]\tTime 0.31 (0.32)\tLoss 0.67 (0.51)\n",
      "\t\tcls_loss 0.38 (0.25)\treg_loss 0.29 (0.26)\n",
      "Epoch: [005][00240/00247]\tTime 0.31 (0.32)\tLoss 0.64 (0.52)\n",
      "\t\tcls_loss 0.32 (0.26)\treg_loss 0.31 (0.26)\n",
      "[Train]: Epoch 5 finished with lr=0.00009875\n",
      "\n",
      "\n",
      "[Train]: Epoch 6 started\n",
      "Epoch: [006][00010/00247]\tTime 0.36 (0.36)\tLoss 0.07 (0.07)\n",
      "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
      "Epoch: [006][00020/00247]\tTime 0.31 (0.33)\tLoss 0.42 (0.25)\n",
      "\t\tcls_loss 0.22 (0.12)\treg_loss 0.21 (0.12)\n",
      "Epoch: [006][00030/00247]\tTime 0.31 (0.33)\tLoss 0.77 (0.42)\n",
      "\t\tcls_loss 0.42 (0.22)\treg_loss 0.34 (0.20)\n",
      "Epoch: [006][00040/00247]\tTime 0.31 (0.32)\tLoss 0.72 (0.50)\n",
      "\t\tcls_loss 0.31 (0.24)\treg_loss 0.41 (0.25)\n",
      "Epoch: [006][00050/00247]\tTime 0.32 (0.32)\tLoss 0.87 (0.57)\n",
      "\t\tcls_loss 0.44 (0.28)\treg_loss 0.43 (0.29)\n",
      "Epoch: [006][00060/00247]\tTime 0.31 (0.32)\tLoss 0.36 (0.54)\n",
      "\t\tcls_loss 0.17 (0.27)\treg_loss 0.18 (0.27)\n",
      "Epoch: [006][00070/00247]\tTime 0.32 (0.32)\tLoss 0.40 (0.52)\n",
      "\t\tcls_loss 0.17 (0.25)\treg_loss 0.23 (0.26)\n",
      "Epoch: [006][00080/00247]\tTime 0.31 (0.32)\tLoss 0.27 (0.48)\n",
      "\t\tcls_loss 0.13 (0.24)\treg_loss 0.13 (0.25)\n",
      "Epoch: [006][00090/00247]\tTime 0.32 (0.32)\tLoss 0.33 (0.47)\n",
      "\t\tcls_loss 0.16 (0.23)\treg_loss 0.17 (0.24)\n",
      "Epoch: [006][00100/00247]\tTime 0.33 (0.32)\tLoss 0.29 (0.45)\n",
      "\t\tcls_loss 0.15 (0.22)\treg_loss 0.14 (0.23)\n",
      "Epoch: [006][00110/00247]\tTime 0.33 (0.32)\tLoss 0.28 (0.43)\n",
      "\t\tcls_loss 0.16 (0.22)\treg_loss 0.12 (0.22)\n",
      "Epoch: [006][00120/00247]\tTime 0.32 (0.32)\tLoss 0.22 (0.42)\n",
      "\t\tcls_loss 0.11 (0.21)\treg_loss 0.10 (0.21)\n",
      "Epoch: [006][00130/00247]\tTime 0.32 (0.32)\tLoss 1.13 (0.47)\n",
      "\t\tcls_loss 0.54 (0.23)\treg_loss 0.59 (0.24)\n",
      "Epoch: [006][00140/00247]\tTime 0.34 (0.32)\tLoss 0.73 (0.49)\n",
      "\t\tcls_loss 0.36 (0.24)\treg_loss 0.37 (0.25)\n",
      "Epoch: [006][00150/00247]\tTime 0.33 (0.32)\tLoss 0.08 (0.46)\n",
      "\t\tcls_loss 0.05 (0.23)\treg_loss 0.04 (0.23)\n",
      "Epoch: [006][00160/00247]\tTime 0.33 (0.32)\tLoss 0.47 (0.46)\n",
      "\t\tcls_loss 0.27 (0.23)\treg_loss 0.20 (0.23)\n",
      "Epoch: [006][00170/00247]\tTime 0.32 (0.32)\tLoss 0.18 (0.45)\n",
      "\t\tcls_loss 0.09 (0.22)\treg_loss 0.09 (0.22)\n",
      "Epoch: [006][00180/00247]\tTime 0.33 (0.32)\tLoss 0.31 (0.44)\n",
      "\t\tcls_loss 0.13 (0.22)\treg_loss 0.18 (0.22)\n",
      "Epoch: [006][00190/00247]\tTime 0.33 (0.32)\tLoss 0.39 (0.44)\n",
      "\t\tcls_loss 0.17 (0.21)\treg_loss 0.22 (0.22)\n",
      "Epoch: [006][00200/00247]\tTime 0.33 (0.32)\tLoss 0.49 (0.44)\n",
      "\t\tcls_loss 0.19 (0.21)\treg_loss 0.30 (0.23)\n",
      "Epoch: [006][00210/00247]\tTime 0.33 (0.32)\tLoss 0.68 (0.45)\n",
      "\t\tcls_loss 0.37 (0.22)\treg_loss 0.31 (0.23)\n",
      "Epoch: [006][00220/00247]\tTime 0.33 (0.32)\tLoss 1.62 (0.50)\n",
      "\t\tcls_loss 0.75 (0.25)\treg_loss 0.87 (0.26)\n",
      "Epoch: [006][00230/00247]\tTime 0.34 (0.33)\tLoss 0.65 (0.51)\n",
      "\t\tcls_loss 0.26 (0.25)\treg_loss 0.38 (0.26)\n",
      "Epoch: [006][00240/00247]\tTime 0.34 (0.33)\tLoss 0.92 (0.53)\n",
      "\t\tcls_loss 0.41 (0.25)\treg_loss 0.51 (0.27)\n",
      "[Train]: Epoch 6 finished with lr=0.00009505\n",
      "\n",
      "\n",
      "[Train]: Epoch 7 started\n",
      "Epoch: [007][00010/00247]\tTime 0.39 (0.39)\tLoss 0.46 (0.46)\n",
      "\t\tcls_loss 0.21 (0.21)\treg_loss 0.25 (0.25)\n",
      "Epoch: [007][00020/00247]\tTime 0.33 (0.36)\tLoss 0.23 (0.34)\n",
      "\t\tcls_loss 0.11 (0.16)\treg_loss 0.12 (0.19)\n",
      "Epoch: [007][00030/00247]\tTime 0.33 (0.35)\tLoss 1.35 (0.68)\n",
      "\t\tcls_loss 0.63 (0.31)\treg_loss 0.73 (0.37)\n",
      "Epoch: [007][00040/00247]\tTime 0.34 (0.35)\tLoss 0.18 (0.55)\n",
      "\t\tcls_loss 0.08 (0.25)\treg_loss 0.10 (0.30)\n",
      "Epoch: [007][00050/00247]\tTime 0.33 (0.34)\tLoss 0.22 (0.49)\n",
      "\t\tcls_loss 0.10 (0.22)\treg_loss 0.12 (0.26)\n",
      "Epoch: [007][00060/00247]\tTime 0.33 (0.34)\tLoss 0.45 (0.48)\n",
      "\t\tcls_loss 0.19 (0.22)\treg_loss 0.25 (0.26)\n",
      "Epoch: [007][00070/00247]\tTime 0.33 (0.34)\tLoss 0.11 (0.43)\n",
      "\t\tcls_loss 0.06 (0.20)\treg_loss 0.05 (0.23)\n",
      "Epoch: [007][00080/00247]\tTime 0.33 (0.34)\tLoss 0.14 (0.39)\n",
      "\t\tcls_loss 0.07 (0.18)\treg_loss 0.07 (0.21)\n",
      "Epoch: [007][00090/00247]\tTime 0.33 (0.34)\tLoss 0.30 (0.38)\n",
      "\t\tcls_loss 0.16 (0.18)\treg_loss 0.14 (0.20)\n",
      "Epoch: [007][00100/00247]\tTime 0.33 (0.34)\tLoss 0.53 (0.40)\n",
      "\t\tcls_loss 0.26 (0.19)\treg_loss 0.27 (0.21)\n",
      "Epoch: [007][00110/00247]\tTime 0.34 (0.34)\tLoss 0.79 (0.43)\n",
      "\t\tcls_loss 0.37 (0.20)\treg_loss 0.42 (0.23)\n",
      "Epoch: [007][00120/00247]\tTime 0.34 (0.34)\tLoss 0.11 (0.41)\n",
      "\t\tcls_loss 0.05 (0.19)\treg_loss 0.06 (0.22)\n",
      "Epoch: [007][00130/00247]\tTime 0.34 (0.34)\tLoss 0.14 (0.38)\n",
      "\t\tcls_loss 0.07 (0.18)\treg_loss 0.06 (0.20)\n",
      "Epoch: [007][00140/00247]\tTime 0.33 (0.34)\tLoss 1.12 (0.44)\n",
      "\t\tcls_loss 0.52 (0.20)\treg_loss 0.60 (0.23)\n",
      "Epoch: [007][00150/00247]\tTime 0.34 (0.34)\tLoss 0.95 (0.47)\n",
      "\t\tcls_loss 0.45 (0.22)\treg_loss 0.49 (0.25)\n",
      "Epoch: [007][00160/00247]\tTime 0.33 (0.34)\tLoss 0.07 (0.45)\n",
      "\t\tcls_loss 0.03 (0.21)\treg_loss 0.04 (0.24)\n",
      "Epoch: [007][00170/00247]\tTime 0.33 (0.34)\tLoss 1.36 (0.50)\n",
      "\t\tcls_loss 0.62 (0.23)\treg_loss 0.74 (0.27)\n",
      "Epoch: [007][00180/00247]\tTime 0.33 (0.34)\tLoss 0.28 (0.49)\n",
      "\t\tcls_loss 0.16 (0.23)\treg_loss 0.13 (0.26)\n",
      "Epoch: [007][00190/00247]\tTime 0.33 (0.34)\tLoss 0.47 (0.49)\n",
      "\t\tcls_loss 0.21 (0.23)\treg_loss 0.26 (0.26)\n",
      "Epoch: [007][00200/00247]\tTime 0.33 (0.34)\tLoss 0.31 (0.48)\n",
      "\t\tcls_loss 0.14 (0.22)\treg_loss 0.18 (0.25)\n",
      "Epoch: [007][00210/00247]\tTime 0.34 (0.34)\tLoss 0.85 (0.50)\n",
      "\t\tcls_loss 0.41 (0.23)\treg_loss 0.44 (0.26)\n",
      "Epoch: [007][00220/00247]\tTime 0.33 (0.34)\tLoss 0.36 (0.49)\n",
      "\t\tcls_loss 0.17 (0.23)\treg_loss 0.19 (0.26)\n",
      "Epoch: [007][00230/00247]\tTime 0.34 (0.34)\tLoss 0.58 (0.49)\n",
      "\t\tcls_loss 0.26 (0.23)\treg_loss 0.32 (0.26)\n",
      "Epoch: [007][00240/00247]\tTime 0.34 (0.34)\tLoss 0.47 (0.49)\n",
      "\t\tcls_loss 0.22 (0.23)\treg_loss 0.26 (0.26)\n",
      "[Train]: Epoch 7 finished with lr=0.00008909\n",
      "\n",
      "\n",
      "[Train]: Epoch 8 started\n",
      "Epoch: [008][00010/00247]\tTime 0.39 (0.39)\tLoss 0.66 (0.66)\n",
      "\t\tcls_loss 0.35 (0.35)\treg_loss 0.31 (0.31)\n",
      "Epoch: [008][00020/00247]\tTime 0.34 (0.36)\tLoss 0.26 (0.46)\n",
      "\t\tcls_loss 0.13 (0.24)\treg_loss 0.13 (0.22)\n",
      "Epoch: [008][00030/00247]\tTime 0.33 (0.35)\tLoss 0.55 (0.49)\n",
      "\t\tcls_loss 0.26 (0.25)\treg_loss 0.29 (0.24)\n",
      "Epoch: [008][00040/00247]\tTime 0.35 (0.35)\tLoss 0.27 (0.43)\n",
      "\t\tcls_loss 0.13 (0.22)\treg_loss 0.14 (0.22)\n",
      "Epoch: [008][00050/00247]\tTime 0.34 (0.35)\tLoss 0.84 (0.52)\n",
      "\t\tcls_loss 0.40 (0.25)\treg_loss 0.44 (0.26)\n",
      "Epoch: [008][00060/00247]\tTime 0.34 (0.35)\tLoss 0.47 (0.51)\n",
      "\t\tcls_loss 0.27 (0.26)\treg_loss 0.20 (0.25)\n",
      "Epoch: [008][00070/00247]\tTime 0.32 (0.35)\tLoss 0.35 (0.49)\n",
      "\t\tcls_loss 0.18 (0.25)\treg_loss 0.17 (0.24)\n",
      "Epoch: [008][00080/00247]\tTime 0.34 (0.35)\tLoss 0.22 (0.45)\n",
      "\t\tcls_loss 0.12 (0.23)\treg_loss 0.10 (0.22)\n",
      "Epoch: [008][00090/00247]\tTime 0.34 (0.34)\tLoss 0.60 (0.47)\n",
      "\t\tcls_loss 0.29 (0.24)\treg_loss 0.32 (0.23)\n",
      "Epoch: [008][00100/00247]\tTime 0.32 (0.34)\tLoss 0.14 (0.44)\n",
      "\t\tcls_loss 0.07 (0.22)\treg_loss 0.07 (0.22)\n",
      "Epoch: [008][00110/00247]\tTime 0.34 (0.34)\tLoss 1.13 (0.50)\n",
      "\t\tcls_loss 0.59 (0.25)\treg_loss 0.54 (0.25)\n",
      "Epoch: [008][00120/00247]\tTime 0.33 (0.34)\tLoss 1.08 (0.55)\n",
      "\t\tcls_loss 0.56 (0.28)\treg_loss 0.52 (0.27)\n",
      "Epoch: [008][00130/00247]\tTime 0.32 (0.34)\tLoss 0.34 (0.53)\n",
      "\t\tcls_loss 0.14 (0.27)\treg_loss 0.20 (0.26)\n",
      "Epoch: [008][00140/00247]\tTime 0.32 (0.34)\tLoss 0.05 (0.50)\n",
      "\t\tcls_loss 0.02 (0.25)\treg_loss 0.03 (0.25)\n",
      "Epoch: [008][00150/00247]\tTime 0.33 (0.34)\tLoss 1.15 (0.54)\n",
      "\t\tcls_loss 0.52 (0.27)\treg_loss 0.63 (0.27)\n",
      "Epoch: [008][00160/00247]\tTime 0.33 (0.34)\tLoss 0.38 (0.53)\n",
      "\t\tcls_loss 0.19 (0.26)\treg_loss 0.18 (0.27)\n",
      "Epoch: [008][00170/00247]\tTime 0.33 (0.34)\tLoss 0.62 (0.54)\n",
      "\t\tcls_loss 0.29 (0.27)\treg_loss 0.33 (0.27)\n",
      "Epoch: [008][00180/00247]\tTime 0.34 (0.34)\tLoss 0.27 (0.52)\n",
      "\t\tcls_loss 0.12 (0.26)\treg_loss 0.15 (0.26)\n",
      "Epoch: [008][00190/00247]\tTime 0.32 (0.34)\tLoss 0.29 (0.51)\n",
      "\t\tcls_loss 0.15 (0.25)\treg_loss 0.13 (0.26)\n",
      "Epoch: [008][00200/00247]\tTime 0.33 (0.34)\tLoss 0.08 (0.49)\n",
      "\t\tcls_loss 0.05 (0.24)\treg_loss 0.03 (0.25)\n",
      "Epoch: [008][00210/00247]\tTime 0.32 (0.33)\tLoss 1.40 (0.53)\n",
      "\t\tcls_loss 0.67 (0.26)\treg_loss 0.72 (0.27)\n",
      "Epoch: [008][00220/00247]\tTime 0.32 (0.33)\tLoss 0.75 (0.54)\n",
      "\t\tcls_loss 0.38 (0.27)\treg_loss 0.37 (0.27)\n",
      "Epoch: [008][00230/00247]\tTime 0.32 (0.33)\tLoss 0.55 (0.54)\n",
      "\t\tcls_loss 0.26 (0.27)\treg_loss 0.29 (0.27)\n",
      "Epoch: [008][00240/00247]\tTime 0.32 (0.33)\tLoss 1.25 (0.57)\n",
      "\t\tcls_loss 0.56 (0.28)\treg_loss 0.69 (0.29)\n",
      "[Train]: Epoch 8 finished with lr=0.00008118\n",
      "\n",
      "\n",
      "[Train]: Epoch 9 started\n",
      "Epoch: [009][00010/00247]\tTime 0.36 (0.36)\tLoss 0.26 (0.26)\n",
      "\t\tcls_loss 0.12 (0.12)\treg_loss 0.14 (0.14)\n",
      "Epoch: [009][00020/00247]\tTime 0.33 (0.34)\tLoss 0.34 (0.30)\n",
      "\t\tcls_loss 0.15 (0.13)\treg_loss 0.19 (0.16)\n",
      "Epoch: [009][00030/00247]\tTime 0.34 (0.34)\tLoss 0.36 (0.32)\n",
      "\t\tcls_loss 0.19 (0.15)\treg_loss 0.17 (0.16)\n",
      "Epoch: [009][00040/00247]\tTime 0.34 (0.34)\tLoss 0.77 (0.43)\n",
      "\t\tcls_loss 0.37 (0.21)\treg_loss 0.40 (0.22)\n",
      "Epoch: [009][00050/00247]\tTime 0.32 (0.34)\tLoss 0.71 (0.49)\n",
      "\t\tcls_loss 0.32 (0.23)\treg_loss 0.38 (0.26)\n",
      "Epoch: [009][00060/00247]\tTime 0.32 (0.33)\tLoss 1.04 (0.58)\n",
      "\t\tcls_loss 0.47 (0.27)\treg_loss 0.57 (0.31)\n",
      "Epoch: [009][00070/00247]\tTime 0.32 (0.33)\tLoss 1.13 (0.66)\n",
      "\t\tcls_loss 0.50 (0.30)\treg_loss 0.63 (0.35)\n",
      "Epoch: [009][00080/00247]\tTime 0.33 (0.33)\tLoss 0.03 (0.58)\n",
      "\t\tcls_loss 0.02 (0.27)\treg_loss 0.01 (0.31)\n",
      "Epoch: [009][00090/00247]\tTime 0.33 (0.33)\tLoss 0.72 (0.59)\n",
      "\t\tcls_loss 0.38 (0.28)\treg_loss 0.33 (0.31)\n",
      "Epoch: [009][00100/00247]\tTime 0.32 (0.33)\tLoss 0.34 (0.57)\n",
      "\t\tcls_loss 0.17 (0.27)\treg_loss 0.17 (0.30)\n",
      "Epoch: [009][00110/00247]\tTime 0.33 (0.33)\tLoss 0.93 (0.60)\n",
      "\t\tcls_loss 0.51 (0.29)\treg_loss 0.43 (0.31)\n",
      "Epoch: [009][00120/00247]\tTime 0.32 (0.33)\tLoss 0.08 (0.56)\n",
      "\t\tcls_loss 0.04 (0.27)\treg_loss 0.04 (0.29)\n",
      "Epoch: [009][00130/00247]\tTime 0.32 (0.33)\tLoss 0.83 (0.58)\n",
      "\t\tcls_loss 0.41 (0.28)\treg_loss 0.43 (0.30)\n",
      "Epoch: [009][00140/00247]\tTime 0.32 (0.33)\tLoss 0.40 (0.57)\n",
      "\t\tcls_loss 0.21 (0.28)\treg_loss 0.18 (0.29)\n",
      "Epoch: [009][00150/00247]\tTime 0.32 (0.33)\tLoss 0.64 (0.57)\n",
      "\t\tcls_loss 0.31 (0.28)\treg_loss 0.33 (0.29)\n",
      "Epoch: [009][00160/00247]\tTime 0.32 (0.33)\tLoss 0.37 (0.56)\n",
      "\t\tcls_loss 0.19 (0.27)\treg_loss 0.18 (0.29)\n",
      "Epoch: [009][00170/00247]\tTime 0.33 (0.33)\tLoss 0.95 (0.58)\n",
      "\t\tcls_loss 0.48 (0.28)\treg_loss 0.47 (0.30)\n",
      "Epoch: [009][00180/00247]\tTime 0.34 (0.33)\tLoss 0.20 (0.56)\n",
      "\t\tcls_loss 0.11 (0.27)\treg_loss 0.09 (0.29)\n",
      "Epoch: [009][00190/00247]\tTime 0.34 (0.33)\tLoss 0.14 (0.54)\n",
      "\t\tcls_loss 0.07 (0.26)\treg_loss 0.07 (0.27)\n",
      "Epoch: [009][00200/00247]\tTime 0.32 (0.33)\tLoss 0.20 (0.52)\n",
      "\t\tcls_loss 0.10 (0.26)\treg_loss 0.09 (0.27)\n",
      "Epoch: [009][00210/00247]\tTime 0.32 (0.33)\tLoss 0.03 (0.50)\n",
      "\t\tcls_loss 0.02 (0.24)\treg_loss 0.01 (0.25)\n",
      "Epoch: [009][00220/00247]\tTime 0.32 (0.33)\tLoss 0.57 (0.50)\n",
      "\t\tcls_loss 0.28 (0.25)\treg_loss 0.29 (0.26)\n",
      "Epoch: [009][00230/00247]\tTime 0.32 (0.33)\tLoss 0.02 (0.48)\n",
      "\t\tcls_loss 0.01 (0.24)\treg_loss 0.01 (0.24)\n",
      "Epoch: [009][00240/00247]\tTime 0.33 (0.33)\tLoss 0.54 (0.48)\n",
      "\t\tcls_loss 0.23 (0.24)\treg_loss 0.30 (0.25)\n",
      "[Train]: Epoch 9 finished with lr=0.00007170\n",
      "\n",
      "\n",
      "[Train]: Epoch 10 started\n",
      "Epoch: [010][00010/00247]\tTime 0.36 (0.36)\tLoss 0.44 (0.44)\n",
      "\t\tcls_loss 0.22 (0.22)\treg_loss 0.22 (0.22)\n",
      "Epoch: [010][00020/00247]\tTime 0.33 (0.35)\tLoss 0.19 (0.32)\n",
      "\t\tcls_loss 0.11 (0.17)\treg_loss 0.08 (0.15)\n",
      "Epoch: [010][00030/00247]\tTime 0.32 (0.34)\tLoss 0.17 (0.27)\n",
      "\t\tcls_loss 0.10 (0.15)\treg_loss 0.07 (0.12)\n",
      "Epoch: [010][00040/00247]\tTime 0.32 (0.33)\tLoss 0.30 (0.28)\n",
      "\t\tcls_loss 0.14 (0.15)\treg_loss 0.16 (0.13)\n",
      "Epoch: [010][00050/00247]\tTime 0.32 (0.33)\tLoss 0.09 (0.24)\n",
      "\t\tcls_loss 0.05 (0.13)\treg_loss 0.04 (0.11)\n",
      "Epoch: [010][00060/00247]\tTime 0.32 (0.33)\tLoss 0.18 (0.23)\n",
      "\t\tcls_loss 0.10 (0.12)\treg_loss 0.08 (0.11)\n",
      "Epoch: [010][00070/00247]\tTime 0.32 (0.33)\tLoss 0.09 (0.21)\n",
      "\t\tcls_loss 0.04 (0.11)\treg_loss 0.05 (0.10)\n",
      "Epoch: [010][00080/00247]\tTime 0.33 (0.33)\tLoss 0.49 (0.24)\n",
      "\t\tcls_loss 0.26 (0.13)\treg_loss 0.23 (0.11)\n",
      "Epoch: [010][00090/00247]\tTime 0.33 (0.33)\tLoss 0.66 (0.29)\n",
      "\t\tcls_loss 0.29 (0.15)\treg_loss 0.37 (0.14)\n",
      "Epoch: [010][00100/00247]\tTime 0.34 (0.33)\tLoss 0.73 (0.34)\n",
      "\t\tcls_loss 0.33 (0.17)\treg_loss 0.40 (0.17)\n",
      "Epoch: [010][00110/00247]\tTime 0.33 (0.33)\tLoss 0.38 (0.34)\n",
      "\t\tcls_loss 0.18 (0.17)\treg_loss 0.20 (0.17)\n",
      "Epoch: [010][00120/00247]\tTime 0.33 (0.33)\tLoss 0.15 (0.32)\n",
      "\t\tcls_loss 0.07 (0.16)\treg_loss 0.08 (0.16)\n",
      "Epoch: [010][00130/00247]\tTime 0.32 (0.33)\tLoss 0.30 (0.32)\n",
      "\t\tcls_loss 0.13 (0.16)\treg_loss 0.17 (0.16)\n",
      "Epoch: [010][00140/00247]\tTime 0.32 (0.33)\tLoss 1.73 (0.42)\n",
      "\t\tcls_loss 0.79 (0.20)\treg_loss 0.93 (0.22)\n",
      "Epoch: [010][00150/00247]\tTime 0.34 (0.33)\tLoss 0.52 (0.43)\n",
      "\t\tcls_loss 0.26 (0.21)\treg_loss 0.27 (0.22)\n",
      "Epoch: [010][00160/00247]\tTime 0.33 (0.33)\tLoss 0.58 (0.44)\n",
      "\t\tcls_loss 0.28 (0.21)\treg_loss 0.30 (0.23)\n",
      "Epoch: [010][00170/00247]\tTime 0.33 (0.33)\tLoss 0.67 (0.45)\n",
      "\t\tcls_loss 0.31 (0.22)\treg_loss 0.36 (0.24)\n",
      "Epoch: [010][00180/00247]\tTime 0.33 (0.33)\tLoss 0.43 (0.45)\n",
      "\t\tcls_loss 0.23 (0.22)\treg_loss 0.20 (0.23)\n",
      "Epoch: [010][00190/00247]\tTime 0.33 (0.33)\tLoss 0.75 (0.47)\n",
      "\t\tcls_loss 0.39 (0.23)\treg_loss 0.36 (0.24)\n",
      "Epoch: [010][00200/00247]\tTime 0.33 (0.33)\tLoss 0.63 (0.48)\n",
      "\t\tcls_loss 0.33 (0.23)\treg_loss 0.30 (0.24)\n",
      "Epoch: [010][00210/00247]\tTime 0.32 (0.33)\tLoss 0.07 (0.46)\n",
      "\t\tcls_loss 0.04 (0.22)\treg_loss 0.04 (0.23)\n",
      "Epoch: [010][00220/00247]\tTime 0.32 (0.33)\tLoss 1.21 (0.49)\n",
      "\t\tcls_loss 0.58 (0.24)\treg_loss 0.62 (0.25)\n",
      "Epoch: [010][00230/00247]\tTime 0.33 (0.33)\tLoss 0.67 (0.50)\n",
      "\t\tcls_loss 0.31 (0.24)\treg_loss 0.36 (0.26)\n",
      "Epoch: [010][00240/00247]\tTime 0.33 (0.33)\tLoss 0.42 (0.49)\n",
      "\t\tcls_loss 0.19 (0.24)\treg_loss 0.23 (0.25)\n",
      "[Train]: Epoch 10 finished with lr=0.00006113\n",
      "\n",
      "\n",
      "[Train]: Epoch 11 started\n",
      "Epoch: [011][00010/00247]\tTime 0.36 (0.36)\tLoss 0.44 (0.44)\n",
      "\t\tcls_loss 0.21 (0.21)\treg_loss 0.23 (0.23)\n",
      "Epoch: [011][00020/00247]\tTime 0.32 (0.34)\tLoss 0.24 (0.34)\n",
      "\t\tcls_loss 0.12 (0.16)\treg_loss 0.12 (0.17)\n",
      "Epoch: [011][00030/00247]\tTime 0.32 (0.33)\tLoss 0.34 (0.34)\n",
      "\t\tcls_loss 0.16 (0.16)\treg_loss 0.18 (0.18)\n",
      "Epoch: [011][00040/00247]\tTime 0.32 (0.33)\tLoss 0.21 (0.31)\n",
      "\t\tcls_loss 0.11 (0.15)\treg_loss 0.10 (0.16)\n",
      "Epoch: [011][00050/00247]\tTime 0.32 (0.33)\tLoss 0.14 (0.27)\n",
      "\t\tcls_loss 0.08 (0.13)\treg_loss 0.06 (0.14)\n",
      "Epoch: [011][00060/00247]\tTime 0.32 (0.32)\tLoss 0.40 (0.29)\n",
      "\t\tcls_loss 0.19 (0.14)\treg_loss 0.21 (0.15)\n",
      "Epoch: [011][00070/00247]\tTime 0.32 (0.32)\tLoss 0.42 (0.31)\n",
      "\t\tcls_loss 0.20 (0.15)\treg_loss 0.23 (0.16)\n",
      "Epoch: [011][00080/00247]\tTime 0.31 (0.32)\tLoss 0.16 (0.29)\n",
      "\t\tcls_loss 0.07 (0.14)\treg_loss 0.08 (0.15)\n",
      "Epoch: [011][00090/00247]\tTime 0.32 (0.32)\tLoss 0.73 (0.34)\n",
      "\t\tcls_loss 0.37 (0.17)\treg_loss 0.36 (0.18)\n",
      "Epoch: [011][00100/00247]\tTime 0.34 (0.32)\tLoss 0.56 (0.36)\n",
      "\t\tcls_loss 0.27 (0.18)\treg_loss 0.29 (0.19)\n",
      "Epoch: [011][00110/00247]\tTime 0.33 (0.32)\tLoss 0.37 (0.36)\n",
      "\t\tcls_loss 0.19 (0.18)\treg_loss 0.18 (0.19)\n",
      "Epoch: [011][00120/00247]\tTime 0.33 (0.32)\tLoss 0.56 (0.38)\n",
      "\t\tcls_loss 0.28 (0.19)\treg_loss 0.28 (0.19)\n",
      "Epoch: [011][00130/00247]\tTime 0.32 (0.32)\tLoss 0.09 (0.36)\n",
      "\t\tcls_loss 0.05 (0.18)\treg_loss 0.05 (0.18)\n",
      "Epoch: [011][00140/00247]\tTime 0.32 (0.32)\tLoss 0.70 (0.38)\n",
      "\t\tcls_loss 0.31 (0.19)\treg_loss 0.39 (0.20)\n",
      "Epoch: [011][00150/00247]\tTime 0.33 (0.32)\tLoss 0.12 (0.37)\n",
      "\t\tcls_loss 0.06 (0.18)\treg_loss 0.07 (0.19)\n",
      "Epoch: [011][00160/00247]\tTime 0.32 (0.32)\tLoss 0.73 (0.39)\n",
      "\t\tcls_loss 0.34 (0.19)\treg_loss 0.39 (0.20)\n",
      "Epoch: [011][00170/00247]\tTime 0.33 (0.32)\tLoss 0.36 (0.39)\n",
      "\t\tcls_loss 0.17 (0.19)\treg_loss 0.19 (0.20)\n",
      "Epoch: [011][00180/00247]\tTime 0.33 (0.32)\tLoss 0.47 (0.39)\n",
      "\t\tcls_loss 0.23 (0.19)\treg_loss 0.24 (0.20)\n",
      "Epoch: [011][00190/00247]\tTime 0.31 (0.32)\tLoss 0.74 (0.41)\n",
      "\t\tcls_loss 0.39 (0.20)\treg_loss 0.35 (0.21)\n",
      "Epoch: [011][00200/00247]\tTime 0.33 (0.32)\tLoss 0.96 (0.44)\n",
      "\t\tcls_loss 0.40 (0.21)\treg_loss 0.56 (0.23)\n",
      "Epoch: [011][00210/00247]\tTime 0.33 (0.32)\tLoss 0.22 (0.43)\n",
      "\t\tcls_loss 0.11 (0.20)\treg_loss 0.11 (0.22)\n",
      "Epoch: [011][00220/00247]\tTime 0.34 (0.33)\tLoss 0.86 (0.45)\n",
      "\t\tcls_loss 0.41 (0.21)\treg_loss 0.45 (0.23)\n",
      "Epoch: [011][00230/00247]\tTime 0.33 (0.33)\tLoss 0.88 (0.47)\n",
      "\t\tcls_loss 0.44 (0.22)\treg_loss 0.44 (0.24)\n",
      "Epoch: [011][00240/00247]\tTime 0.33 (0.33)\tLoss 0.34 (0.46)\n",
      "\t\tcls_loss 0.20 (0.22)\treg_loss 0.15 (0.24)\n",
      "[Train]: Epoch 11 finished with lr=0.00005000\n",
      "\n",
      "\n",
      "[Train]: Epoch 12 started\n",
      "Epoch: [012][00010/00247]\tTime 0.36 (0.36)\tLoss 0.45 (0.45)\n",
      "\t\tcls_loss 0.27 (0.27)\treg_loss 0.17 (0.17)\n",
      "Epoch: [012][00020/00247]\tTime 0.33 (0.34)\tLoss 0.40 (0.42)\n",
      "\t\tcls_loss 0.20 (0.23)\treg_loss 0.20 (0.19)\n",
      "Epoch: [012][00030/00247]\tTime 0.32 (0.34)\tLoss 0.36 (0.40)\n",
      "\t\tcls_loss 0.18 (0.22)\treg_loss 0.18 (0.19)\n",
      "Epoch: [012][00040/00247]\tTime 0.32 (0.33)\tLoss 0.09 (0.32)\n",
      "\t\tcls_loss 0.05 (0.17)\treg_loss 0.05 (0.15)\n",
      "Epoch: [012][00050/00247]\tTime 0.33 (0.33)\tLoss 0.62 (0.38)\n",
      "\t\tcls_loss 0.26 (0.19)\treg_loss 0.35 (0.19)\n",
      "Epoch: [012][00060/00247]\tTime 0.32 (0.33)\tLoss 0.25 (0.36)\n",
      "\t\tcls_loss 0.11 (0.18)\treg_loss 0.14 (0.18)\n",
      "Epoch: [012][00070/00247]\tTime 0.32 (0.33)\tLoss 0.29 (0.35)\n",
      "\t\tcls_loss 0.17 (0.18)\treg_loss 0.12 (0.17)\n",
      "Epoch: [012][00080/00247]\tTime 0.32 (0.33)\tLoss 0.88 (0.42)\n",
      "\t\tcls_loss 0.37 (0.20)\treg_loss 0.51 (0.22)\n",
      "Epoch: [012][00090/00247]\tTime 0.32 (0.33)\tLoss 0.66 (0.44)\n",
      "\t\tcls_loss 0.29 (0.21)\treg_loss 0.37 (0.23)\n",
      "Epoch: [012][00100/00247]\tTime 0.32 (0.33)\tLoss 0.25 (0.42)\n",
      "\t\tcls_loss 0.13 (0.20)\treg_loss 0.12 (0.22)\n",
      "Epoch: [012][00110/00247]\tTime 0.33 (0.33)\tLoss 0.24 (0.41)\n",
      "\t\tcls_loss 0.13 (0.20)\treg_loss 0.11 (0.21)\n",
      "Epoch: [012][00120/00247]\tTime 0.32 (0.33)\tLoss 0.57 (0.42)\n",
      "\t\tcls_loss 0.29 (0.20)\treg_loss 0.29 (0.22)\n",
      "Epoch: [012][00130/00247]\tTime 0.32 (0.33)\tLoss 0.29 (0.41)\n",
      "\t\tcls_loss 0.13 (0.20)\treg_loss 0.16 (0.21)\n",
      "Epoch: [012][00140/00247]\tTime 0.32 (0.33)\tLoss 1.03 (0.46)\n",
      "\t\tcls_loss 0.47 (0.22)\treg_loss 0.56 (0.24)\n",
      "Epoch: [012][00150/00247]\tTime 0.33 (0.33)\tLoss 0.26 (0.44)\n",
      "\t\tcls_loss 0.12 (0.21)\treg_loss 0.14 (0.23)\n",
      "Epoch: [012][00160/00247]\tTime 0.32 (0.33)\tLoss 0.77 (0.46)\n",
      "\t\tcls_loss 0.35 (0.22)\treg_loss 0.43 (0.24)\n",
      "Epoch: [012][00170/00247]\tTime 0.33 (0.33)\tLoss 0.42 (0.46)\n",
      "\t\tcls_loss 0.24 (0.22)\treg_loss 0.18 (0.24)\n",
      "Epoch: [012][00180/00247]\tTime 0.34 (0.33)\tLoss 0.43 (0.46)\n",
      "\t\tcls_loss 0.24 (0.22)\treg_loss 0.19 (0.24)\n",
      "Epoch: [012][00190/00247]\tTime 0.33 (0.33)\tLoss 0.92 (0.48)\n",
      "\t\tcls_loss 0.44 (0.23)\treg_loss 0.49 (0.25)\n",
      "Epoch: [012][00200/00247]\tTime 0.33 (0.33)\tLoss 0.74 (0.50)\n",
      "\t\tcls_loss 0.36 (0.24)\treg_loss 0.39 (0.26)\n",
      "Epoch: [012][00210/00247]\tTime 0.33 (0.33)\tLoss 1.25 (0.53)\n",
      "\t\tcls_loss 0.58 (0.25)\treg_loss 0.68 (0.28)\n",
      "Epoch: [012][00220/00247]\tTime 0.32 (0.33)\tLoss 0.61 (0.54)\n",
      "\t\tcls_loss 0.29 (0.26)\treg_loss 0.33 (0.28)\n",
      "Epoch: [012][00230/00247]\tTime 0.32 (0.33)\tLoss 0.26 (0.52)\n",
      "\t\tcls_loss 0.15 (0.25)\treg_loss 0.11 (0.27)\n",
      "Epoch: [012][00240/00247]\tTime 0.32 (0.33)\tLoss 0.90 (0.54)\n",
      "\t\tcls_loss 0.40 (0.26)\treg_loss 0.50 (0.28)\n",
      "[Train]: Epoch 12 finished with lr=0.00003888\n",
      "\n",
      "\n",
      "[Train]: Epoch 13 started\n",
      "Epoch: [013][00010/00247]\tTime 0.35 (0.35)\tLoss 0.54 (0.54)\n",
      "\t\tcls_loss 0.26 (0.26)\treg_loss 0.28 (0.28)\n",
      "Epoch: [013][00020/00247]\tTime 0.32 (0.34)\tLoss 0.49 (0.51)\n",
      "\t\tcls_loss 0.24 (0.25)\treg_loss 0.24 (0.26)\n",
      "Epoch: [013][00030/00247]\tTime 0.32 (0.33)\tLoss 0.07 (0.37)\n",
      "\t\tcls_loss 0.04 (0.18)\treg_loss 0.03 (0.18)\n",
      "Epoch: [013][00040/00247]\tTime 0.33 (0.33)\tLoss 1.18 (0.57)\n",
      "\t\tcls_loss 0.57 (0.28)\treg_loss 0.62 (0.29)\n",
      "Epoch: [013][00050/00247]\tTime 0.33 (0.33)\tLoss 0.30 (0.52)\n",
      "\t\tcls_loss 0.13 (0.25)\treg_loss 0.17 (0.27)\n",
      "Epoch: [013][00060/00247]\tTime 0.34 (0.33)\tLoss 0.68 (0.54)\n",
      "\t\tcls_loss 0.33 (0.26)\treg_loss 0.35 (0.28)\n",
      "Epoch: [013][00070/00247]\tTime 0.34 (0.33)\tLoss 0.57 (0.55)\n",
      "\t\tcls_loss 0.28 (0.27)\treg_loss 0.29 (0.28)\n",
      "Epoch: [013][00080/00247]\tTime 0.34 (0.33)\tLoss 0.35 (0.52)\n",
      "\t\tcls_loss 0.15 (0.25)\treg_loss 0.20 (0.27)\n",
      "Epoch: [013][00090/00247]\tTime 0.32 (0.33)\tLoss 0.04 (0.47)\n",
      "\t\tcls_loss 0.02 (0.23)\treg_loss 0.02 (0.24)\n",
      "Epoch: [013][00100/00247]\tTime 0.32 (0.33)\tLoss 0.41 (0.46)\n",
      "\t\tcls_loss 0.21 (0.22)\treg_loss 0.20 (0.24)\n",
      "Epoch: [013][00110/00247]\tTime 0.32 (0.33)\tLoss 0.22 (0.44)\n",
      "\t\tcls_loss 0.12 (0.21)\treg_loss 0.10 (0.23)\n",
      "Epoch: [013][00120/00247]\tTime 0.32 (0.33)\tLoss 0.52 (0.45)\n",
      "\t\tcls_loss 0.26 (0.22)\treg_loss 0.26 (0.23)\n",
      "Epoch: [013][00130/00247]\tTime 0.32 (0.33)\tLoss 0.41 (0.44)\n",
      "\t\tcls_loss 0.18 (0.22)\treg_loss 0.22 (0.23)\n",
      "Epoch: [013][00140/00247]\tTime 0.32 (0.33)\tLoss 0.59 (0.45)\n",
      "\t\tcls_loss 0.34 (0.22)\treg_loss 0.25 (0.23)\n",
      "Epoch: [013][00150/00247]\tTime 0.32 (0.33)\tLoss 0.06 (0.43)\n",
      "\t\tcls_loss 0.03 (0.21)\treg_loss 0.03 (0.22)\n",
      "Epoch: [013][00160/00247]\tTime 0.32 (0.33)\tLoss 0.15 (0.41)\n",
      "\t\tcls_loss 0.08 (0.20)\treg_loss 0.07 (0.21)\n",
      "Epoch: [013][00170/00247]\tTime 0.31 (0.33)\tLoss 0.15 (0.40)\n",
      "\t\tcls_loss 0.07 (0.19)\treg_loss 0.08 (0.20)\n",
      "Epoch: [013][00180/00247]\tTime 0.32 (0.33)\tLoss 0.27 (0.39)\n",
      "\t\tcls_loss 0.15 (0.19)\treg_loss 0.12 (0.20)\n",
      "Epoch: [013][00190/00247]\tTime 0.33 (0.33)\tLoss 0.25 (0.38)\n",
      "\t\tcls_loss 0.13 (0.19)\treg_loss 0.12 (0.19)\n",
      "Epoch: [013][00200/00247]\tTime 0.33 (0.33)\tLoss 0.35 (0.38)\n",
      "\t\tcls_loss 0.20 (0.19)\treg_loss 0.14 (0.19)\n",
      "Epoch: [013][00210/00247]\tTime 0.32 (0.33)\tLoss 0.69 (0.39)\n",
      "\t\tcls_loss 0.34 (0.20)\treg_loss 0.35 (0.20)\n",
      "Epoch: [013][00220/00247]\tTime 0.34 (0.33)\tLoss 1.17 (0.43)\n",
      "\t\tcls_loss 0.53 (0.21)\treg_loss 0.64 (0.22)\n",
      "Epoch: [013][00230/00247]\tTime 0.32 (0.33)\tLoss 0.30 (0.42)\n",
      "\t\tcls_loss 0.16 (0.21)\treg_loss 0.14 (0.21)\n",
      "Epoch: [013][00240/00247]\tTime 0.32 (0.33)\tLoss 0.41 (0.42)\n",
      "\t\tcls_loss 0.22 (0.21)\treg_loss 0.19 (0.21)\n",
      "[Train]: Epoch 13 finished with lr=0.00002831\n",
      "\n",
      "\n",
      "[Train]: Epoch 14 started\n",
      "Epoch: [014][00010/00247]\tTime 0.38 (0.38)\tLoss 0.09 (0.09)\n",
      "\t\tcls_loss 0.05 (0.05)\treg_loss 0.04 (0.04)\n",
      "Epoch: [014][00020/00247]\tTime 0.32 (0.35)\tLoss 0.56 (0.33)\n",
      "\t\tcls_loss 0.31 (0.18)\treg_loss 0.25 (0.14)\n",
      "Epoch: [014][00030/00247]\tTime 0.33 (0.35)\tLoss 0.85 (0.50)\n",
      "\t\tcls_loss 0.44 (0.27)\treg_loss 0.41 (0.23)\n",
      "Epoch: [014][00040/00247]\tTime 0.33 (0.34)\tLoss 0.27 (0.44)\n",
      "\t\tcls_loss 0.13 (0.23)\treg_loss 0.14 (0.21)\n",
      "Epoch: [014][00050/00247]\tTime 0.32 (0.34)\tLoss 0.18 (0.39)\n",
      "\t\tcls_loss 0.10 (0.21)\treg_loss 0.08 (0.18)\n",
      "Epoch: [014][00060/00247]\tTime 0.33 (0.34)\tLoss 0.54 (0.42)\n",
      "\t\tcls_loss 0.26 (0.22)\treg_loss 0.27 (0.20)\n",
      "Epoch: [014][00070/00247]\tTime 0.32 (0.33)\tLoss 0.08 (0.37)\n",
      "\t\tcls_loss 0.04 (0.19)\treg_loss 0.04 (0.18)\n",
      "Epoch: [014][00080/00247]\tTime 0.32 (0.33)\tLoss 0.41 (0.37)\n",
      "\t\tcls_loss 0.19 (0.19)\treg_loss 0.22 (0.18)\n",
      "Epoch: [014][00090/00247]\tTime 0.31 (0.33)\tLoss 0.49 (0.39)\n",
      "\t\tcls_loss 0.27 (0.20)\treg_loss 0.22 (0.18)\n",
      "Epoch: [014][00100/00247]\tTime 0.31 (0.33)\tLoss 1.10 (0.46)\n",
      "\t\tcls_loss 0.49 (0.23)\treg_loss 0.61 (0.23)\n",
      "Epoch: [014][00110/00247]\tTime 0.32 (0.33)\tLoss 0.27 (0.44)\n",
      "\t\tcls_loss 0.12 (0.22)\treg_loss 0.14 (0.22)\n",
      "Epoch: [014][00120/00247]\tTime 0.32 (0.33)\tLoss 0.48 (0.44)\n",
      "\t\tcls_loss 0.24 (0.22)\treg_loss 0.24 (0.22)\n",
      "Epoch: [014][00130/00247]\tTime 0.32 (0.33)\tLoss 0.48 (0.45)\n",
      "\t\tcls_loss 0.26 (0.23)\treg_loss 0.22 (0.22)\n",
      "Epoch: [014][00140/00247]\tTime 0.32 (0.33)\tLoss 0.54 (0.45)\n",
      "\t\tcls_loss 0.29 (0.23)\treg_loss 0.25 (0.22)\n",
      "Epoch: [014][00150/00247]\tTime 0.33 (0.33)\tLoss 0.10 (0.43)\n",
      "\t\tcls_loss 0.06 (0.22)\treg_loss 0.05 (0.21)\n",
      "Epoch: [014][00160/00247]\tTime 0.32 (0.33)\tLoss 0.77 (0.45)\n",
      "\t\tcls_loss 0.39 (0.23)\treg_loss 0.38 (0.22)\n",
      "Epoch: [014][00170/00247]\tTime 0.32 (0.33)\tLoss 0.19 (0.44)\n",
      "\t\tcls_loss 0.10 (0.22)\treg_loss 0.09 (0.21)\n",
      "Epoch: [014][00180/00247]\tTime 0.33 (0.33)\tLoss 0.13 (0.42)\n",
      "\t\tcls_loss 0.08 (0.21)\treg_loss 0.05 (0.20)\n",
      "Epoch: [014][00190/00247]\tTime 0.34 (0.33)\tLoss 0.08 (0.40)\n",
      "\t\tcls_loss 0.05 (0.21)\treg_loss 0.04 (0.20)\n",
      "Epoch: [014][00200/00247]\tTime 0.33 (0.33)\tLoss 0.55 (0.41)\n",
      "\t\tcls_loss 0.28 (0.21)\treg_loss 0.26 (0.20)\n",
      "Epoch: [014][00210/00247]\tTime 0.33 (0.33)\tLoss 0.70 (0.42)\n",
      "\t\tcls_loss 0.36 (0.22)\treg_loss 0.34 (0.21)\n",
      "Epoch: [014][00220/00247]\tTime 0.32 (0.33)\tLoss 0.29 (0.42)\n",
      "\t\tcls_loss 0.13 (0.21)\treg_loss 0.16 (0.20)\n",
      "Epoch: [014][00230/00247]\tTime 0.32 (0.33)\tLoss 0.73 (0.43)\n",
      "\t\tcls_loss 0.34 (0.22)\treg_loss 0.38 (0.21)\n",
      "Epoch: [014][00240/00247]\tTime 0.32 (0.33)\tLoss 0.03 (0.41)\n",
      "\t\tcls_loss 0.02 (0.21)\treg_loss 0.02 (0.20)\n",
      "[Train]: Epoch 14 finished with lr=0.00001883\n",
      "\n",
      "\n",
      "[Train]: Epoch 15 started\n",
      "Epoch: [015][00010/00247]\tTime 0.38 (0.38)\tLoss 0.31 (0.31)\n",
      "\t\tcls_loss 0.17 (0.17)\treg_loss 0.14 (0.14)\n",
      "Epoch: [015][00020/00247]\tTime 0.34 (0.36)\tLoss 0.23 (0.27)\n",
      "\t\tcls_loss 0.14 (0.15)\treg_loss 0.09 (0.11)\n",
      "Epoch: [015][00030/00247]\tTime 0.34 (0.36)\tLoss 0.11 (0.22)\n",
      "\t\tcls_loss 0.07 (0.13)\treg_loss 0.04 (0.09)\n",
      "Epoch: [015][00040/00247]\tTime 0.33 (0.35)\tLoss 0.59 (0.31)\n",
      "\t\tcls_loss 0.26 (0.16)\treg_loss 0.32 (0.15)\n",
      "Epoch: [015][00050/00247]\tTime 0.33 (0.35)\tLoss 0.02 (0.25)\n",
      "\t\tcls_loss 0.01 (0.13)\treg_loss 0.01 (0.12)\n",
      "Epoch: [015][00060/00247]\tTime 0.32 (0.34)\tLoss 0.22 (0.24)\n",
      "\t\tcls_loss 0.12 (0.13)\treg_loss 0.10 (0.12)\n",
      "Epoch: [015][00070/00247]\tTime 0.32 (0.34)\tLoss 0.02 (0.21)\n",
      "\t\tcls_loss 0.01 (0.11)\treg_loss 0.01 (0.10)\n",
      "Epoch: [015][00080/00247]\tTime 0.33 (0.34)\tLoss 0.89 (0.30)\n",
      "\t\tcls_loss 0.41 (0.15)\treg_loss 0.48 (0.15)\n",
      "Epoch: [015][00090/00247]\tTime 0.33 (0.34)\tLoss 0.29 (0.30)\n",
      "\t\tcls_loss 0.16 (0.15)\treg_loss 0.14 (0.15)\n",
      "Epoch: [015][00100/00247]\tTime 0.33 (0.34)\tLoss 0.07 (0.27)\n",
      "\t\tcls_loss 0.04 (0.14)\treg_loss 0.03 (0.14)\n",
      "Epoch: [015][00110/00247]\tTime 0.32 (0.34)\tLoss 0.29 (0.28)\n",
      "\t\tcls_loss 0.14 (0.14)\treg_loss 0.15 (0.14)\n",
      "Epoch: [015][00120/00247]\tTime 0.33 (0.33)\tLoss 0.66 (0.31)\n",
      "\t\tcls_loss 0.33 (0.16)\treg_loss 0.32 (0.15)\n",
      "Epoch: [015][00130/00247]\tTime 0.32 (0.33)\tLoss 0.32 (0.31)\n",
      "\t\tcls_loss 0.17 (0.16)\treg_loss 0.14 (0.15)\n",
      "Epoch: [015][00140/00247]\tTime 0.34 (0.33)\tLoss 0.20 (0.30)\n",
      "\t\tcls_loss 0.12 (0.15)\treg_loss 0.08 (0.15)\n",
      "Epoch: [015][00150/00247]\tTime 0.34 (0.33)\tLoss 0.05 (0.28)\n",
      "\t\tcls_loss 0.03 (0.15)\treg_loss 0.03 (0.14)\n",
      "Epoch: [015][00160/00247]\tTime 0.34 (0.33)\tLoss 0.32 (0.29)\n",
      "\t\tcls_loss 0.17 (0.15)\treg_loss 0.15 (0.14)\n",
      "Epoch: [015][00170/00247]\tTime 0.34 (0.34)\tLoss 1.17 (0.34)\n",
      "\t\tcls_loss 0.55 (0.17)\treg_loss 0.62 (0.17)\n",
      "Epoch: [015][00180/00247]\tTime 0.34 (0.34)\tLoss 0.22 (0.33)\n",
      "\t\tcls_loss 0.13 (0.17)\treg_loss 0.09 (0.16)\n",
      "Epoch: [015][00190/00247]\tTime 0.33 (0.33)\tLoss 0.58 (0.34)\n",
      "\t\tcls_loss 0.28 (0.17)\treg_loss 0.30 (0.17)\n",
      "Epoch: [015][00200/00247]\tTime 0.34 (0.34)\tLoss 0.24 (0.34)\n",
      "\t\tcls_loss 0.13 (0.17)\treg_loss 0.11 (0.17)\n",
      "Epoch: [015][00210/00247]\tTime 0.34 (0.34)\tLoss 0.55 (0.35)\n",
      "\t\tcls_loss 0.26 (0.18)\treg_loss 0.29 (0.17)\n",
      "Epoch: [015][00220/00247]\tTime 0.33 (0.34)\tLoss 0.15 (0.34)\n",
      "\t\tcls_loss 0.09 (0.17)\treg_loss 0.06 (0.17)\n",
      "Epoch: [015][00230/00247]\tTime 0.34 (0.34)\tLoss 0.17 (0.33)\n",
      "\t\tcls_loss 0.10 (0.17)\treg_loss 0.07 (0.16)\n",
      "Epoch: [015][00240/00247]\tTime 0.33 (0.34)\tLoss 0.40 (0.34)\n",
      "\t\tcls_loss 0.19 (0.17)\treg_loss 0.21 (0.17)\n",
      "[Train]: Epoch 15 finished with lr=0.00001092\n",
      "\n",
      "\n",
      "[Train]: Epoch 16 started\n",
      "Epoch: [016][00010/00247]\tTime 0.36 (0.36)\tLoss 0.03 (0.03)\n",
      "\t\tcls_loss 0.02 (0.02)\treg_loss 0.01 (0.01)\n",
      "Epoch: [016][00020/00247]\tTime 0.32 (0.34)\tLoss 0.13 (0.08)\n",
      "\t\tcls_loss 0.09 (0.05)\treg_loss 0.05 (0.03)\n",
      "Epoch: [016][00030/00247]\tTime 0.32 (0.34)\tLoss 0.15 (0.11)\n",
      "\t\tcls_loss 0.08 (0.06)\treg_loss 0.07 (0.04)\n",
      "Epoch: [016][00040/00247]\tTime 0.32 (0.33)\tLoss 0.03 (0.09)\n",
      "\t\tcls_loss 0.02 (0.05)\treg_loss 0.01 (0.04)\n",
      "Epoch: [016][00050/00247]\tTime 0.34 (0.33)\tLoss 0.30 (0.13)\n",
      "\t\tcls_loss 0.17 (0.07)\treg_loss 0.13 (0.05)\n",
      "Epoch: [016][00060/00247]\tTime 0.33 (0.33)\tLoss 0.16 (0.13)\n",
      "\t\tcls_loss 0.09 (0.08)\treg_loss 0.07 (0.06)\n",
      "Epoch: [016][00070/00247]\tTime 0.32 (0.33)\tLoss 1.20 (0.29)\n",
      "\t\tcls_loss 0.55 (0.14)\treg_loss 0.65 (0.14)\n",
      "Epoch: [016][00080/00247]\tTime 0.32 (0.33)\tLoss 0.49 (0.31)\n",
      "\t\tcls_loss 0.26 (0.16)\treg_loss 0.23 (0.15)\n",
      "Epoch: [016][00090/00247]\tTime 0.32 (0.33)\tLoss 0.06 (0.28)\n",
      "\t\tcls_loss 0.03 (0.14)\treg_loss 0.03 (0.14)\n",
      "Epoch: [016][00100/00247]\tTime 0.32 (0.33)\tLoss 0.05 (0.26)\n",
      "\t\tcls_loss 0.03 (0.13)\treg_loss 0.02 (0.13)\n",
      "Epoch: [016][00110/00247]\tTime 0.32 (0.33)\tLoss 0.26 (0.26)\n",
      "\t\tcls_loss 0.15 (0.14)\treg_loss 0.10 (0.13)\n",
      "Epoch: [016][00120/00247]\tTime 0.32 (0.33)\tLoss 0.16 (0.25)\n",
      "\t\tcls_loss 0.08 (0.13)\treg_loss 0.08 (0.12)\n",
      "Epoch: [016][00130/00247]\tTime 0.32 (0.33)\tLoss 0.30 (0.26)\n",
      "\t\tcls_loss 0.17 (0.13)\treg_loss 0.14 (0.12)\n",
      "Epoch: [016][00140/00247]\tTime 0.32 (0.33)\tLoss 0.21 (0.25)\n",
      "\t\tcls_loss 0.09 (0.13)\treg_loss 0.11 (0.12)\n",
      "Epoch: [016][00150/00247]\tTime 0.32 (0.33)\tLoss 0.20 (0.25)\n",
      "\t\tcls_loss 0.11 (0.13)\treg_loss 0.09 (0.12)\n",
      "Epoch: [016][00160/00247]\tTime 0.32 (0.33)\tLoss 0.13 (0.24)\n",
      "\t\tcls_loss 0.08 (0.13)\treg_loss 0.05 (0.12)\n",
      "Epoch: [016][00170/00247]\tTime 0.32 (0.32)\tLoss 0.40 (0.25)\n",
      "\t\tcls_loss 0.22 (0.13)\treg_loss 0.18 (0.12)\n",
      "Epoch: [016][00180/00247]\tTime 0.32 (0.32)\tLoss 0.56 (0.27)\n",
      "\t\tcls_loss 0.27 (0.14)\treg_loss 0.29 (0.13)\n",
      "Epoch: [016][00190/00247]\tTime 0.32 (0.32)\tLoss 0.19 (0.26)\n",
      "\t\tcls_loss 0.12 (0.14)\treg_loss 0.07 (0.13)\n",
      "Epoch: [016][00200/00247]\tTime 0.32 (0.32)\tLoss 0.36 (0.27)\n",
      "\t\tcls_loss 0.19 (0.14)\treg_loss 0.16 (0.13)\n",
      "Epoch: [016][00210/00247]\tTime 0.32 (0.32)\tLoss 0.42 (0.28)\n",
      "\t\tcls_loss 0.24 (0.15)\treg_loss 0.18 (0.13)\n",
      "Epoch: [016][00220/00247]\tTime 0.32 (0.32)\tLoss 0.50 (0.29)\n",
      "\t\tcls_loss 0.25 (0.15)\treg_loss 0.24 (0.14)\n",
      "Epoch: [016][00230/00247]\tTime 0.32 (0.32)\tLoss 0.06 (0.28)\n",
      "\t\tcls_loss 0.04 (0.15)\treg_loss 0.02 (0.13)\n",
      "Epoch: [016][00240/00247]\tTime 0.32 (0.32)\tLoss 0.10 (0.27)\n",
      "\t\tcls_loss 0.05 (0.14)\treg_loss 0.05 (0.13)\n",
      "[Train]: Epoch 16 finished with lr=0.00000496\n",
      "\n",
      "\n",
      "[Train]: Epoch 17 started\n",
      "Epoch: [017][00010/00247]\tTime 0.37 (0.37)\tLoss 0.31 (0.31)\n",
      "\t\tcls_loss 0.16 (0.16)\treg_loss 0.16 (0.16)\n",
      "Epoch: [017][00020/00247]\tTime 0.33 (0.35)\tLoss 0.29 (0.30)\n",
      "\t\tcls_loss 0.17 (0.16)\treg_loss 0.12 (0.14)\n",
      "Epoch: [017][00030/00247]\tTime 0.32 (0.34)\tLoss 0.06 (0.22)\n",
      "\t\tcls_loss 0.04 (0.12)\treg_loss 0.02 (0.10)\n",
      "Epoch: [017][00040/00247]\tTime 0.32 (0.34)\tLoss 0.27 (0.24)\n",
      "\t\tcls_loss 0.15 (0.13)\treg_loss 0.12 (0.11)\n",
      "Epoch: [017][00050/00247]\tTime 0.32 (0.33)\tLoss 0.23 (0.23)\n",
      "\t\tcls_loss 0.12 (0.13)\treg_loss 0.11 (0.11)\n",
      "Epoch: [017][00060/00247]\tTime 0.32 (0.33)\tLoss 0.52 (0.28)\n",
      "\t\tcls_loss 0.26 (0.15)\treg_loss 0.26 (0.13)\n",
      "Epoch: [017][00070/00247]\tTime 0.32 (0.33)\tLoss 0.53 (0.32)\n",
      "\t\tcls_loss 0.26 (0.17)\treg_loss 0.27 (0.15)\n",
      "Epoch: [017][00080/00247]\tTime 0.32 (0.33)\tLoss 0.09 (0.29)\n",
      "\t\tcls_loss 0.06 (0.15)\treg_loss 0.03 (0.14)\n",
      "Epoch: [017][00090/00247]\tTime 0.32 (0.33)\tLoss 0.03 (0.26)\n",
      "\t\tcls_loss 0.01 (0.14)\treg_loss 0.02 (0.12)\n",
      "Epoch: [017][00100/00247]\tTime 0.33 (0.33)\tLoss 0.62 (0.30)\n",
      "\t\tcls_loss 0.28 (0.15)\treg_loss 0.33 (0.14)\n",
      "Epoch: [017][00110/00247]\tTime 0.32 (0.33)\tLoss 0.09 (0.28)\n",
      "\t\tcls_loss 0.05 (0.14)\treg_loss 0.04 (0.13)\n",
      "Epoch: [017][00120/00247]\tTime 0.32 (0.33)\tLoss 0.23 (0.27)\n",
      "\t\tcls_loss 0.13 (0.14)\treg_loss 0.10 (0.13)\n",
      "Epoch: [017][00130/00247]\tTime 0.32 (0.33)\tLoss 0.72 (0.31)\n",
      "\t\tcls_loss 0.37 (0.16)\treg_loss 0.34 (0.15)\n",
      "Epoch: [017][00140/00247]\tTime 0.32 (0.33)\tLoss 0.28 (0.30)\n",
      "\t\tcls_loss 0.16 (0.16)\treg_loss 0.11 (0.15)\n",
      "Epoch: [017][00150/00247]\tTime 0.33 (0.33)\tLoss 0.07 (0.29)\n",
      "\t\tcls_loss 0.04 (0.15)\treg_loss 0.03 (0.14)\n",
      "Epoch: [017][00160/00247]\tTime 0.32 (0.33)\tLoss 0.16 (0.28)\n",
      "\t\tcls_loss 0.08 (0.15)\treg_loss 0.07 (0.13)\n",
      "Epoch: [017][00170/00247]\tTime 0.34 (0.33)\tLoss 0.09 (0.27)\n",
      "\t\tcls_loss 0.06 (0.14)\treg_loss 0.04 (0.13)\n",
      "Epoch: [017][00180/00247]\tTime 0.32 (0.33)\tLoss 0.40 (0.28)\n",
      "\t\tcls_loss 0.20 (0.15)\treg_loss 0.19 (0.13)\n",
      "Epoch: [017][00190/00247]\tTime 0.32 (0.33)\tLoss 0.24 (0.27)\n",
      "\t\tcls_loss 0.13 (0.14)\treg_loss 0.11 (0.13)\n",
      "Epoch: [017][00200/00247]\tTime 0.32 (0.32)\tLoss 0.28 (0.27)\n",
      "\t\tcls_loss 0.15 (0.14)\treg_loss 0.12 (0.13)\n",
      "Epoch: [017][00210/00247]\tTime 0.32 (0.32)\tLoss 0.11 (0.27)\n",
      "\t\tcls_loss 0.06 (0.14)\treg_loss 0.05 (0.13)\n",
      "Epoch: [017][00220/00247]\tTime 0.32 (0.32)\tLoss 0.33 (0.27)\n",
      "\t\tcls_loss 0.16 (0.14)\treg_loss 0.16 (0.13)\n",
      "Epoch: [017][00230/00247]\tTime 0.32 (0.32)\tLoss 0.19 (0.27)\n",
      "\t\tcls_loss 0.09 (0.14)\treg_loss 0.10 (0.13)\n",
      "Epoch: [017][00240/00247]\tTime 0.32 (0.32)\tLoss 0.73 (0.29)\n",
      "\t\tcls_loss 0.32 (0.15)\treg_loss 0.41 (0.14)\n",
      "[Train]: Epoch 17 finished with lr=0.00000126\n",
      "\n",
      "\n",
      "[Train]: Epoch 18 started\n",
      "Epoch: [018][00010/00247]\tTime 0.39 (0.39)\tLoss 0.80 (0.80)\n",
      "\t\tcls_loss 0.38 (0.38)\treg_loss 0.42 (0.42)\n",
      "Epoch: [018][00020/00247]\tTime 0.34 (0.36)\tLoss 0.34 (0.57)\n",
      "\t\tcls_loss 0.20 (0.29)\treg_loss 0.15 (0.29)\n",
      "Epoch: [018][00030/00247]\tTime 0.32 (0.35)\tLoss 0.68 (0.61)\n",
      "\t\tcls_loss 0.33 (0.30)\treg_loss 0.35 (0.31)\n",
      "Epoch: [018][00040/00247]\tTime 0.33 (0.35)\tLoss 0.05 (0.47)\n",
      "\t\tcls_loss 0.03 (0.23)\treg_loss 0.02 (0.23)\n",
      "Epoch: [018][00050/00247]\tTime 0.34 (0.35)\tLoss 0.36 (0.45)\n",
      "\t\tcls_loss 0.21 (0.23)\treg_loss 0.15 (0.22)\n",
      "Epoch: [018][00060/00247]\tTime 0.34 (0.34)\tLoss 0.17 (0.40)\n",
      "\t\tcls_loss 0.09 (0.21)\treg_loss 0.07 (0.19)\n",
      "Epoch: [018][00070/00247]\tTime 0.34 (0.34)\tLoss 0.91 (0.47)\n",
      "\t\tcls_loss 0.40 (0.23)\treg_loss 0.50 (0.24)\n",
      "Epoch: [018][00080/00247]\tTime 0.34 (0.34)\tLoss 0.48 (0.47)\n",
      "\t\tcls_loss 0.25 (0.24)\treg_loss 0.23 (0.24)\n",
      "Epoch: [018][00090/00247]\tTime 0.33 (0.34)\tLoss 0.10 (0.43)\n",
      "\t\tcls_loss 0.05 (0.22)\treg_loss 0.05 (0.22)\n",
      "Epoch: [018][00100/00247]\tTime 0.33 (0.34)\tLoss 0.10 (0.40)\n",
      "\t\tcls_loss 0.06 (0.20)\treg_loss 0.04 (0.20)\n",
      "Epoch: [018][00110/00247]\tTime 0.33 (0.34)\tLoss 0.32 (0.39)\n",
      "\t\tcls_loss 0.17 (0.20)\treg_loss 0.14 (0.19)\n",
      "Epoch: [018][00120/00247]\tTime 0.35 (0.34)\tLoss 0.12 (0.37)\n",
      "\t\tcls_loss 0.06 (0.19)\treg_loss 0.06 (0.18)\n",
      "Epoch: [018][00130/00247]\tTime 0.34 (0.34)\tLoss 0.39 (0.37)\n",
      "\t\tcls_loss 0.19 (0.19)\treg_loss 0.20 (0.18)\n",
      "Epoch: [018][00140/00247]\tTime 0.34 (0.34)\tLoss 0.25 (0.36)\n",
      "\t\tcls_loss 0.14 (0.18)\treg_loss 0.11 (0.18)\n",
      "Epoch: [018][00150/00247]\tTime 0.32 (0.34)\tLoss 0.46 (0.37)\n",
      "\t\tcls_loss 0.22 (0.18)\treg_loss 0.24 (0.18)\n",
      "Epoch: [018][00160/00247]\tTime 0.32 (0.34)\tLoss 0.80 (0.39)\n",
      "\t\tcls_loss 0.42 (0.20)\treg_loss 0.39 (0.20)\n",
      "Epoch: [018][00170/00247]\tTime 0.32 (0.34)\tLoss 0.26 (0.39)\n",
      "\t\tcls_loss 0.12 (0.20)\treg_loss 0.14 (0.19)\n",
      "Epoch: [018][00180/00247]\tTime 0.33 (0.34)\tLoss 0.54 (0.40)\n",
      "\t\tcls_loss 0.29 (0.20)\treg_loss 0.25 (0.20)\n",
      "Epoch: [018][00190/00247]\tTime 0.32 (0.34)\tLoss 0.87 (0.42)\n",
      "\t\tcls_loss 0.41 (0.21)\treg_loss 0.46 (0.21)\n",
      "Epoch: [018][00200/00247]\tTime 0.32 (0.33)\tLoss 0.33 (0.42)\n",
      "\t\tcls_loss 0.18 (0.21)\treg_loss 0.15 (0.21)\n",
      "Epoch: [018][00210/00247]\tTime 0.32 (0.33)\tLoss 0.12 (0.40)\n",
      "\t\tcls_loss 0.08 (0.20)\treg_loss 0.05 (0.20)\n",
      "Epoch: [018][00220/00247]\tTime 0.32 (0.33)\tLoss 0.58 (0.41)\n",
      "\t\tcls_loss 0.28 (0.21)\treg_loss 0.30 (0.20)\n",
      "Epoch: [018][00230/00247]\tTime 0.32 (0.33)\tLoss 0.07 (0.40)\n",
      "\t\tcls_loss 0.05 (0.20)\treg_loss 0.02 (0.20)\n",
      "Epoch: [018][00240/00247]\tTime 0.32 (0.33)\tLoss 0.83 (0.41)\n",
      "\t\tcls_loss 0.34 (0.21)\treg_loss 0.48 (0.21)\n",
      "[Train]: Epoch 18 finished with lr=0.00000001\n",
      "\n",
      "All done!\n",
      "start testing...\n",
      "{'dataset': {'crop_ratio': [0.9, 1.0],\n",
      "             'default_fps': 30,\n",
      "             'downsample_rate': 1,\n",
      "             'feat_folder': './data/epic_kitchens/features',\n",
      "             'feat_stride': 16,\n",
      "             'file_ext': '.npz',\n",
      "             'file_prefix': None,\n",
      "             'force_upsampling': False,\n",
      "             'input_dim': 2304,\n",
      "             'json_file': './data/epic_kitchens/annotations/epic_kitchens_100_noun.json',\n",
      "             'max_seq_len': 2304,\n",
      "             'num_classes': 300,\n",
      "             'num_frames': 32,\n",
      "             'trunc_thresh': 0.3},\n",
      " 'dataset_name': 'epic',\n",
      " 'devices': ['cuda:0'],\n",
      " 'init_rand_seed': 1234567891,\n",
      " 'loader': {'batch_size': 2, 'num_workers': 4},\n",
      " 'model': {'backbone_arch': (2, 2, 5),\n",
      "           'backbone_type': 'SGP',\n",
      "           'boudary_kernel_size': 3,\n",
      "           'downsample_type': 'max',\n",
      "           'embd_dim': 512,\n",
      "           'embd_kernel_size': 3,\n",
      "           'embd_with_ln': True,\n",
      "           'fpn_dim': 512,\n",
      "           'fpn_type': 'identity',\n",
      "           'fpn_with_ln': True,\n",
      "           'head_dim': 512,\n",
      "           'head_kernel_size': 3,\n",
      "           'head_num_layers': 3,\n",
      "           'head_with_ln': True,\n",
      "           'init_conv_vars': 0,\n",
      "           'input_dim': 2304,\n",
      "           'input_noise': 0,\n",
      "           'iou_weight_power': 0.25,\n",
      "           'k': 4,\n",
      "           'max_buffer_len_factor': 4.0,\n",
      "           'max_seq_len': 2304,\n",
      "           'n_sgp_win_size': 1,\n",
      "           'num_bins': 16,\n",
      "           'num_classes': 300,\n",
      "           'regression_range': [[0, 4],\n",
      "                                [2, 8],\n",
      "                                [4, 16],\n",
      "                                [8, 32],\n",
      "                                [16, 64],\n",
      "                                [32, 10000]],\n",
      "           'scale_factor': 2,\n",
      "           'sgp_mlp_dim': 1024,\n",
      "           'test_cfg': {'duration_thresh': 0.05,\n",
      "                        'ext_score_file': None,\n",
      "                        'iou_threshold': 0.1,\n",
      "                        'max_seg_num': 2000,\n",
      "                        'min_score': 0.001,\n",
      "                        'multiclass_nms': True,\n",
      "                        'nms_method': 'soft',\n",
      "                        'nms_sigma': 0.4,\n",
      "                        'pre_nms_thresh': 0.001,\n",
      "                        'pre_nms_topk': 5000,\n",
      "                        'voting_thresh': 0.75},\n",
      "           'train_cfg': {'center_sample': 'radius',\n",
      "                         'center_sample_radius': 1.5,\n",
      "                         'clip_grad_l2norm': 1.0,\n",
      "                         'cls_prior_prob': 0.01,\n",
      "                         'dropout': 0.0,\n",
      "                         'droppath': 0.1,\n",
      "                         'head_empty_cls': [],\n",
      "                         'init_loss_norm': 250,\n",
      "                         'label_smoothing': 0.1,\n",
      "                         'loss_weight': 1.0},\n",
      "           'use_abs_pe': False,\n",
      "           'use_trident_head': True},\n",
      " 'model_name': 'TriDet',\n",
      " 'opt': {'epochs': 14,\n",
      "         'eta_min': 1e-08,\n",
      "         'learning_rate': 0.0001,\n",
      "         'momentum': 0.9,\n",
      "         'schedule_gamma': 0.1,\n",
      "         'schedule_steps': [],\n",
      "         'schedule_type': 'cosine',\n",
      "         'type': 'AdamW',\n",
      "         'warmup': True,\n",
      "         'warmup_epochs': 5,\n",
      "         'weight_decay': 0.05},\n",
      " 'output_folder': './ckpt/',\n",
      " 'test_cfg': {'duration_thresh': 0.05,\n",
      "              'ext_score_file': None,\n",
      "              'iou_threshold': 0.1,\n",
      "              'max_seg_num': 2000,\n",
      "              'min_score': 0.001,\n",
      "              'multiclass_nms': True,\n",
      "              'nms_method': 'soft',\n",
      "              'nms_sigma': 0.4,\n",
      "              'pre_nms_thresh': 0.001,\n",
      "              'pre_nms_topk': 5000,\n",
      "              'voting_thresh': 0.75},\n",
      " 'train_cfg': {'center_sample': 'radius',\n",
      "               'center_sample_radius': 1.5,\n",
      "               'clip_grad_l2norm': 1.0,\n",
      "               'cls_prior_prob': 0.01,\n",
      "               'dropout': 0.0,\n",
      "               'droppath': 0.1,\n",
      "               'head_empty_cls': [],\n",
      "               'init_loss_norm': 250,\n",
      "               'label_smoothing': 0.1,\n",
      "               'loss_weight': 1.0},\n",
      " 'train_split': ['training'],\n",
      " 'val_split': ['validation']}\n",
      "=> loading checkpoint 'ckpt/epic_slowfast_noun_pretrained/epoch_018.pth.tar'\n",
      "Loading from EMA model ...\n",
      "\n",
      "Start testing model TriDet ...\n",
      "Test: [00010/00138]\tTime 0.39 (0.39)\n",
      "Test: [00020/00138]\tTime 0.16 (0.28)\n",
      "Test: [00030/00138]\tTime 0.18 (0.25)\n",
      "Test: [00040/00138]\tTime 0.16 (0.22)\n",
      "Test: [00050/00138]\tTime 0.16 (0.21)\n",
      "Test: [00060/00138]\tTime 0.16 (0.20)\n",
      "Test: [00070/00138]\tTime 0.19 (0.20)\n",
      "Test: [00080/00138]\tTime 0.17 (0.20)\n",
      "Test: [00090/00138]\tTime 0.19 (0.20)\n",
      "Test: [00100/00138]\tTime 0.17 (0.19)\n",
      "Test: [00110/00138]\tTime 0.17 (0.19)\n",
      "Test: [00120/00138]\tTime 0.18 (0.19)\n",
      "Test: [00130/00138]\tTime 0.17 (0.19)\n",
      "Saved!\n",
      "Warning: No predictions of label '205' were provdied.\n",
      "Warning: No predictions of label '240' were provdied.\n",
      "Warning: No predictions of label '288' were provdied.\n",
      "[RESULTS] Action detection results on epic_kitchens_100_noun.\n",
      "\n",
      "|tIoU = 0.10: mAP = 26.54 (%)\n",
      "|tIoU = 0.20: mAP = 25.59 (%)\n",
      "|tIoU = 0.30: mAP = 23.59 (%)\n",
      "|tIoU = 0.40: mAP = 21.37 (%)\n",
      "|tIoU = 0.50: mAP = 17.96 (%)\n",
      "Avearge mAP: 23.01 (%)\n",
      "All done! Total time: 52.27 sec\n"
     ]
    }
   ],
   "source": [
    "!bash /home/featurize/TriDet/tools/epic_noun_slowfast_script.sh 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2839c59-211f-4c2a-8ec4-4c97857e1c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
